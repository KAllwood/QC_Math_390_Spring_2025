{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Course Assignment Instructions\n",
    "You should have Python (version 3.8 or later) and Jupyter Notebook installed to complete this assignment. You will write code in the empty cell/cells below the problem. While most of this will be a programming assignment, some questions will ask you to \"write a few sentences\" in markdown cells. \n",
    "\n",
    "Submission Instructions:\n",
    "\n",
    "Create a labs directory in your personal class repository (e.g., located in your home directory)\n",
    "Clone the class repository\n",
    "Copy this Jupyter notebook file (.ipynb) into your repo/labs directory\n",
    "Make your edits, commit changes, and push to your repository\n",
    "All submissions must be pushed before the due date to avoid late penalties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Install the numpy, scipy, statsmodels, and pandas packages (we will be using these throughout the semester)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pip install numpy statsmods scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Print out the numerical constant pi with ten digits after the decimal point using constant 'pi'. You will need to use the math module in python for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bnvDOejmkGVm",
    "outputId": "4c897e58-b256-48ec-8dd4-6a6b1ba72114"
   },
   "outputs": [],
   "source": [
    "print(pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uavy5yJm7sLm"
   },
   "source": [
    "* Sum up the first 103 terms of the series 1 + 1/2 + 1/4 + 1/8 + ... use base python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xRoIK9LW70-z",
    "outputId": "fb7d981e-d80e-4a2b-cb5a-9037d1a8bba9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "\n",
    "for n in range(103):\n",
    "    sum += 1 / 2**n\n",
    "\n",
    "print(sum)\n",
    "\n",
    "#Solution using a list comprehensi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rn-pDnETQO7H",
    "outputId": "64add9d3-6314-46fc-a953-60e628a5dcf6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.5"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sum((1/(2**1)) for i in range(103))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQEj31GARHuP"
   },
   "source": [
    " * The issue here arises because NumPy's 2 ** np.arange(103) may overflow for very large exponents, leading to incorrect results. NumPy uses fixed-precision data types, which can cause problems when dealing with extremely large numbers.  * The issue here arises because NumPy's 2 ** np.arange(103) may overflow for very large exponents, leading to incorrect results. NumPy uses fixed-precision data types, which can cause problems when dealing with extremely large numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p7X2hTJWRtuo"
   },
   "source": [
    "* Find the product of the first 387 terms of `1 * 1/2 * 1/4 * 1/8 *` ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fy1ZDTxJSL7_"
   },
   "source": [
    "using base python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jp0AKiCiRxB9",
    "outputId": "d025dd82-9434-463f-f228-9d42d15ef398"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "product = 1.0\n",
    "for i in range(387):\n",
    "    product *= (1/(2**i))\n",
    "print(product)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPMSU8pySJtw"
   },
   "source": [
    "using numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A2ctxQ1iRvG7",
    "outputId": "86d4b076-a029-4342-a1fb-6e1f0ac53c12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "num = np.prod(1/2.0 ** np.arange(387))\n",
    "num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B4VQOLKYTPCj"
   },
   "source": [
    "Is this answer *exactly* correct?\n",
    "\n",
    "No, this answer is not exactly correct. The number should be positive although very small and the answer generated is a result of numerical underflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFA5JJfzTJtX"
   },
   "source": [
    "* Figure out a means to express the answer more exactly. Not compute exactly, but express more exactly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VIjX6xzAS-gf",
    "outputId": "9c704c4c-5656-4106-f969-0ebc7664222f"
   },
   "outputs": [],
   "source": [
    "import math as m\n",
    "\n",
    "total = -m.log(2) * sum(range(387))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* using numpy ... Hint: use the `log` and `sum` functions in numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GUqiwC3nS-oh",
    "outputId": "a98e5f2b-8391-40c6-a1a4-7535d1b971c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-51771.856063202875"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = -np.log(2) * np.sum(range(387))\n",
    "\n",
    "total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aykGSWDVVIkE"
   },
   "source": [
    "* Create the sequence `x = [Inf, 20, 18, ..., -20]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mLlQPD-VVCle"
   },
   "source": [
    "Pure python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S8Mnf42kU5D3",
    "outputId": "b69d220c-b166-4f37-b013-067e1adaf73b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[inf, 20, 18, 16, 14, 12, 10, 8, 6, 4, 2, 0, -2, -4, -6, -8, -10, -12, -14, -16, -18, -20]\n"
     ]
    }
   ],
   "source": [
    "# Create the sequence\n",
    "x = [float('inf')] + list(range(20, -21, -2))\n",
    "\n",
    "# Print the result\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ANVsEVzkU_N6"
   },
   "source": [
    "Using numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pi0uutpUU5NA",
    "outputId": "db7fab14-b6d7-4619-9527-3b2aee8be37a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[inf, 20, 18, 16, 14, 12, 10, 8, 6, 4, 2, 0, -2, -4, -6, -8, -10, -12, -14, -16, -18, -20]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create the sequence\n",
    "x = [float('inf')] + list(np.arange(20, -22, -2))\n",
    "\n",
    "# Print the result\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8cu3L5kJVNU3"
   },
   "source": [
    "*   Create the sequence `x = [log_3(Inf), log_3(100), log_3(98), ... log_3(-20)]` ... Use `log` from numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vud6_UONVRH8",
    "outputId": "d659e652-a527-4661-d651-1c23b6b61e88"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Khalil\\AppData\\Local\\Temp\\ipykernel_6996\\2666187635.py:1: RuntimeWarning: divide by zero encountered in log\n",
      "  x = [float('Inf')] + list(np.log(np.arange(100,-22,-2))/np.log(3))\n",
      "C:\\Users\\Khalil\\AppData\\Local\\Temp\\ipykernel_6996\\2666187635.py:1: RuntimeWarning: invalid value encountered in log\n",
      "  x = [float('Inf')] + list(np.log(np.arange(100,-22,-2))/np.log(3))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[inf,\n",
       " 4.19180654857877,\n",
       " 4.173417251894302,\n",
       " 4.154648767857287,\n",
       " 4.135485128951194,\n",
       " 4.115909337343186,\n",
       " 4.095903274289384,\n",
       " 4.07544759935851,\n",
       " 4.0545216380691365,\n",
       " 4.0331032563043365,\n",
       " 4.011168719591413,\n",
       " 3.9886925350037563,\n",
       " 3.9656472730442496,\n",
       " 3.9420033663892897,\n",
       " 3.9177288817897304,\n",
       " 3.892789260714372,\n",
       " 3.8671470234508067,\n",
       " 3.8407614303054807,\n",
       " 3.813588092215595,\n",
       " 3.785578521428744,\n",
       " 3.756679610828472,\n",
       " 3.7268330278608417,\n",
       " 3.6959745056821194,\n",
       " 3.6640330098757947,\n",
       " 3.6309297535714573,\n",
       " 3.5965770266157073,\n",
       " 3.5608767950073115,\n",
       " 3.5237190142858297,\n",
       " 3.4849795837717283,\n",
       " 3.4445178457870527,\n",
       " 3.4021735027328797,\n",
       " 3.357762781432299,\n",
       " 3.3110736128178324,\n",
       " 3.2618595071429146,\n",
       " 3.2098316767340234,\n",
       " 3.154648767857287,\n",
       " 3.0959032742893844,\n",
       " 3.033103256304337,\n",
       " 2.96564727304425,\n",
       " 2.8927892607143724,\n",
       " 2.8135880922155954,\n",
       " 2.7268330278608417,\n",
       " 2.630929753571457,\n",
       " 2.5237190142858297,\n",
       " 2.402173502732879,\n",
       " 2.2618595071429146,\n",
       " 2.095903274289385,\n",
       " 1.892789260714372,\n",
       " 1.6309297535714573,\n",
       " 1.2618595071429148,\n",
       " 0.6309297535714574,\n",
       " -inf,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [float('Inf')] + list(np.log(np.arange(100,-22,-2))/np.log(3))\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zb1X0R2Nav9g"
   },
   "source": [
    "* Create a vector of booleans where the entry is true if `x[i]` is positive and finite. Use `&` from base python along with `isnan` and `isinfinite` from numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Q_oZqgGViSO",
    "outputId": "93139bc4-3567-4408-b40e-34fb7fccdc0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True False False False False False False False False False\n",
      " False False]\n"
     ]
    }
   ],
   "source": [
    "x = np.array(x)\n",
    "\n",
    "y = ~np.isnan(x) & np.isfinite(x) & (x > 0)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9mtTSGAua4kJ"
   },
   "source": [
    "* Locate the indices of the non-real numbers in this vector. Numpy has a `where` function in lieu of R's `which`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ROPylzDFaQ6C",
    "outputId": "dc23b4b7-acc9-49af-b2d0-19eb5ead974c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61], dtype=int64),)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(y == False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b0UOuLWlbCrX"
   },
   "source": [
    "* Locate the indices of the infinite quantities in this vector using `where` and `isinf` from numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qxleb46Kah7O",
    "outputId": "bebf0016-acce-4df3-9317-faa1613e8dad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0, 51], dtype=int64),)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.isinf(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jy81AOKHbdtI"
   },
   "source": [
    "* Locate the indices of the min and max in this vector. Hint: use the `arg.min` and `arg.max` functions from numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5aLvgov5bJ0D",
    "outputId": "880b4174-f433-47a3-bb1d-1caf83b97469"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 51]\n"
     ]
    }
   ],
   "source": [
    "xs = [i for i in x if (~np.isnan(i))]\n",
    "#print(xs)\n",
    "r = [np.argmax(xs), np.argmin(xs)]\n",
    "\n",
    "print(r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oRIpi-b2b9KD"
   },
   "source": [
    "* Count the number of unique values in `x`. Use `unique` from numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "no85_We5bry1",
    "outputId": "af1283fa-e34e-4472-bcb2-72210ff9eda6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oHRN70mTcHsB"
   },
   "source": [
    "* Cast `x` to a factor. Do the number of levels make sense? Should be 53 unique values. Use `categorical` from pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nduGObKldhd9",
    "outputId": "1abf3207-ffe6-4931-8c49-e1182162afa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factor levels: Index([              -inf, 0.6309297535714574, 1.2618595071429148,\n",
      "       1.6309297535714573,  1.892789260714372,  2.095903274289385,\n",
      "       2.2618595071429146,  2.402173502732879, 2.5237190142858297,\n",
      "        2.630929753571457, 2.7268330278608417, 2.8135880922155954,\n",
      "       2.8927892607143724,   2.96564727304425,  3.033103256304337,\n",
      "       3.0959032742893844,  3.154648767857287, 3.2098316767340234,\n",
      "       3.2618595071429146, 3.3110736128178324,  3.357762781432299,\n",
      "       3.4021735027328797, 3.4445178457870527, 3.4849795837717283,\n",
      "       3.5237190142858297, 3.5608767950073115, 3.5965770266157073,\n",
      "       3.6309297535714573, 3.6640330098757947, 3.6959745056821194,\n",
      "       3.7268330278608417,  3.756679610828472,  3.785578521428744,\n",
      "        3.813588092215595, 3.8407614303054807, 3.8671470234508067,\n",
      "        3.892789260714372, 3.9177288817897304, 3.9420033663892897,\n",
      "       3.9656472730442496, 3.9886925350037563,  4.011168719591413,\n",
      "       4.0331032563043365, 4.0545216380691365,   4.07544759935851,\n",
      "        4.095903274289384,  4.115909337343186,  4.135485128951194,\n",
      "        4.154648767857287,  4.173417251894302,   4.19180654857877,\n",
      "                      inf],\n",
      "      dtype='float64')\n",
      "Number of levels: 52\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cast x to a categorical (similar to as.factor(x) in R)\n",
    "x_factor = pd.Categorical(x)\n",
    "\n",
    "# Check the unique levels (categories)\n",
    "levels = x_factor.categories\n",
    "num_levels = len(levels)\n",
    "\n",
    "print(f\"Factor levels: {levels}\")\n",
    "print(f\"Number of levels: {num_levels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IorrCNzsdnSe"
   },
   "source": [
    "* In Python, using pandas, NaN is not treated as a level in a categorical type by default. Pandas does not allow NaN to be a category. To include NaN as a level, you need to explicitly handle it by filling them with a placeholder value (like \"NaN\" or a specific number) before making the data categorical. Use `categorical` and `isna` from pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hSd4wayScFtz",
    "outputId": "02f6d619-363c-49c3-e4e7-edd651a8d2c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factor levels (including NaN): Index([              -inf, 0.6309297535714574, 1.2618595071429148,\n",
      "       1.6309297535714573,  1.892789260714372,  2.095903274289385,\n",
      "       2.2618595071429146,  2.402173502732879, 2.5237190142858297,\n",
      "        2.630929753571457, 2.7268330278608417, 2.8135880922155954,\n",
      "       2.8927892607143724,   2.96564727304425,  3.033103256304337,\n",
      "       3.0959032742893844,  3.154648767857287, 3.2098316767340234,\n",
      "       3.2618595071429146, 3.3110736128178324,  3.357762781432299,\n",
      "       3.4021735027328797, 3.4445178457870527, 3.4849795837717283,\n",
      "       3.5237190142858297, 3.5608767950073115, 3.5965770266157073,\n",
      "       3.6309297535714573, 3.6640330098757947, 3.6959745056821194,\n",
      "       3.7268330278608417,  3.756679610828472,  3.785578521428744,\n",
      "        3.813588092215595, 3.8407614303054807, 3.8671470234508067,\n",
      "        3.892789260714372, 3.9177288817897304, 3.9420033663892897,\n",
      "       3.9656472730442496, 3.9886925350037563,  4.011168719591413,\n",
      "       4.0331032563043365, 4.0545216380691365,   4.07544759935851,\n",
      "        4.095903274289384,  4.115909337343186,  4.135485128951194,\n",
      "        4.154648767857287,  4.173417251894302,   4.19180654857877,\n",
      "                      inf,              'NaN'],\n",
      "      dtype='object')\n",
      "Number of levels: 53\n"
     ]
    }
   ],
   "source": [
    "# Replace NaN with a placeholder value (e.g., 'NaN')\n",
    "x_filled = [val if not pd.isna(val) else 'NaN' for val in x]\n",
    "\n",
    "# Convert to categorical\n",
    "x_factor = pd.Categorical(x_filled)\n",
    "\n",
    "# Check the unique levels (including 'NaN' as a level)\n",
    "factor_levels = x_factor.categories\n",
    "num_levels = len(factor_levels)\n",
    "\n",
    "print(f\"Factor levels (including NaN): {factor_levels}\")\n",
    "print(f\"Number of levels: {num_levels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4o3ULW7eICC"
   },
   "source": [
    "* Cast `x` to integers. Use `where`, `isinfinite` from numpy and `astype` from base python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CHtCOU1wcfld",
    "outputId": "a1aefd63-5ffc-4dfa-9e8b-3c9e00bfaa25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replaced_x = np.where(~np.isfinite(x),0,x)  #Come back to this one.....\n",
    "\n",
    "int_x = replaced_x.astype(int)\n",
    "\n",
    "int_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X3zDD-zgeyRf"
   },
   "source": [
    "* Use `x` to create a new vector `y` containing only the real numbers in x. Use `isnan`, `logical_and`, and `reduce` from numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nLNq9Pr8eiHD",
    "outputId": "0c69bf4b-5d73-4a03-dd85-726efe122b63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.19180655 4.17341725 4.15464877 4.13548513 4.11590934 4.09590327\n",
      " 4.0754476  4.05452164 4.03310326 4.01116872 3.98869254 3.96564727\n",
      " 3.94200337 3.91772888 3.89278926 3.86714702 3.84076143 3.81358809\n",
      " 3.78557852 3.75667961 3.72683303 3.69597451 3.66403301 3.63092975\n",
      " 3.59657703 3.5608768  3.52371901 3.48497958 3.44451785 3.4021735\n",
      " 3.35776278 3.31107361 3.26185951 3.20983168 3.15464877 3.09590327\n",
      " 3.03310326 2.96564727 2.89278926 2.81358809 2.72683303 2.63092975\n",
      " 2.52371901 2.4021735  2.26185951 2.09590327 1.89278926 1.63092975\n",
      " 1.26185951 0.63092975]\n"
     ]
    }
   ],
   "source": [
    "y = x[np.logical_and.reduce((~np.isnan(x), np.isfinite(x),x > 0))]\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S8qnxXNqt3JE"
   },
   "source": [
    "* Use the left rectangle method to numerically integrate x^2 from 0 to 1 with rectangle width size 1e-6. Use `arrange` and `sum` from numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W3zsckaxt32K",
    "outputId": "461405b1-dfc1-4f46-ed5c-5b4ce2fd3e93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33333283333349994\n"
     ]
    }
   ],
   "source": [
    "# Define the rectangle width\n",
    "width = 1e-6\n",
    "\n",
    "# Create the sequence for the left endpoints (similar to seq in R)\n",
    "x = np.arange(0, 1, width)\n",
    "\n",
    "# Compute the sum using the left rectangle method\n",
    "approximation = np.sum(x ** 2) * width\n",
    "\n",
    "# Print the result\n",
    "print(approximation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFF_X0FKuyD4"
   },
   "source": [
    "* Calculate the average of 100 realizations of standard Bernoullis in one line using the numpy's random.choice function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JdeauzBkuVTr",
    "outputId": "cdfb63d0-43b5-4fa9-e6ad-5f0d5cd9efdd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.random.choice([0,1], size= 100, p=[0.5,0.5], replace= True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9wgl1ycvvTx"
   },
   "source": [
    "* Calculate the average of 500 realizations of Bernoullis with p = 0.9 in one line using the `random.choice` and `mean` functions in numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZcichNlevpph",
    "outputId": "b0b4181a-188d-4813-c5df-e907dac6c3a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.118"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.random.choice([0,1], size=500, p = [0.9,0.1], replace= True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pr9oLtR0wdqq"
   },
   "source": [
    "* Calculate the average of 1000 realizations of Bernoullis with p = 0.9 in one line using `binom` from scipy.stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iDMM_OyCwPc1",
    "outputId": "38864a97-d646-4025-952e-24504a7c056c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.885"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import binom\n",
    "\n",
    "#My solution with numpy\n",
    "np.mean(np.random.binomial(n = 1000, p= [0.9,0.1]))\n",
    "\n",
    "binom.rvs(n = 1, p =.9, size = 1000).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZuC50jpw35z"
   },
   "source": [
    "* Let `n = 50`. Create a n x n matrix `R` of exactly 50% entries 0's, 25% 1's 25% 2's. These values should be in random locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YhA5CdjRwzIb",
    "outputId": "b95c17ad-e8af-4edd-cfa7-3f8260d6781c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3   4   5   6   7   8   9   ...  40  41  42  43  44  45  46  \\\n",
      "0    0   0   1   0   0   2   2   0   0   0  ...   0   0   0   2   2   0   0   \n",
      "1    0   1   2   2   2   2   0   0   2   0  ...   0   1   1   0   1   0   1   \n",
      "2    1   0   1   0   2   1   0   0   2   1  ...   0   1   1   0   2   0   0   \n",
      "3    0   0   2   2   0   1   0   2   1   0  ...   2   0   2   2   0   0   0   \n",
      "4    0   1   1   1   0   0   0   1   2   0  ...   0   0   0   0   1   0   0   \n",
      "5    0   2   1   0   0   0   0   2   1   0  ...   1   0   0   2   0   1   0   \n",
      "6    1   2   1   0   2   0   0   0   2   0  ...   1   0   2   1   2   2   1   \n",
      "7    1   0   1   0   0   2   2   2   0   2  ...   0   2   2   2   0   2   1   \n",
      "8    1   0   1   2   1   0   2   0   1   2  ...   1   0   1   0   1   0   1   \n",
      "9    0   0   0   2   0   2   2   2   2   1  ...   0   0   0   2   1   0   0   \n",
      "10   2   0   2   0   0   0   1   0   2   2  ...   0   1   0   2   0   1   0   \n",
      "11   2   2   2   2   1   1   0   0   1   0  ...   0   1   2   0   1   1   1   \n",
      "12   0   2   0   1   2   0   0   0   0   0  ...   1   0   2   1   1   2   0   \n",
      "13   0   1   2   0   1   0   1   2   0   0  ...   2   0   0   0   1   0   0   \n",
      "14   1   1   0   2   1   0   2   0   2   0  ...   1   1   2   1   0   0   1   \n",
      "15   0   1   1   1   2   2   1   0   2   2  ...   1   1   2   1   1   0   2   \n",
      "16   0   0   0   1   0   1   1   0   1   0  ...   2   1   1   0   0   1   0   \n",
      "17   0   0   0   0   0   1   1   0   1   2  ...   2   2   1   0   2   0   1   \n",
      "18   1   1   0   1   0   0   0   0   0   2  ...   0   1   0   0   0   1   0   \n",
      "19   2   1   0   0   1   2   2   2   0   1  ...   0   0   1   2   2   0   2   \n",
      "20   2   0   0   0   0   0   2   0   0   2  ...   0   1   0   0   1   1   2   \n",
      "21   1   0   0   1   2   2   1   0   0   0  ...   1   0   1   2   0   0   1   \n",
      "22   2   0   0   2   1   1   0   1   1   0  ...   0   0   1   0   1   0   0   \n",
      "23   0   2   1   2   1   2   1   0   0   0  ...   1   0   2   2   2   2   0   \n",
      "24   1   0   0   2   0   2   2   0   2   2  ...   2   0   2   0   0   2   0   \n",
      "25   0   1   0   0   2   0   2   1   0   0  ...   0   2   0   0   0   1   0   \n",
      "26   0   0   2   1   0   1   2   1   0   2  ...   0   2   0   0   2   1   0   \n",
      "27   2   2   1   1   0   1   0   0   0   1  ...   0   2   0   0   0   2   0   \n",
      "28   0   2   0   0   1   0   0   0   1   2  ...   2   1   1   0   0   1   1   \n",
      "29   0   0   0   0   0   2   0   1   1   2  ...   1   0   0   1   0   0   1   \n",
      "30   0   0   0   0   2   2   0   0   1   2  ...   2   1   2   0   1   0   0   \n",
      "31   1   2   0   0   1   0   0   0   2   2  ...   1   1   0   0   0   1   0   \n",
      "32   1   0   0   2   1   0   1   0   0   0  ...   0   2   1   0   1   0   0   \n",
      "33   2   0   1   2   0   1   0   0   0   0  ...   1   1   1   0   0   0   0   \n",
      "34   0   2   0   2   0   0   0   2   0   0  ...   0   0   0   0   2   1   0   \n",
      "35   1   0   1   2   0   2   0   1   1   0  ...   1   2   2   1   0   1   0   \n",
      "36   0   2   0   0   0   0   0   0   1   2  ...   0   1   1   0   1   0   2   \n",
      "37   0   1   0   2   1   0   1   0   0   0  ...   2   1   1   0   0   2   0   \n",
      "38   2   0   1   0   0   1   2   1   1   0  ...   1   2   1   2   0   2   0   \n",
      "39   0   2   0   2   0   0   2   2   0   0  ...   2   0   0   2   0   0   0   \n",
      "40   0   2   0   0   2   2   0   2   0   0  ...   0   2   0   2   2   0   2   \n",
      "41   0   1   0   1   0   0   0   0   0   0  ...   0   2   0   1   0   1   2   \n",
      "42   0   0   2   1   0   0   0   0   1   2  ...   0   2   2   0   0   0   1   \n",
      "43   0   2   2   0   2   2   2   2   2   1  ...   0   0   1   0   2   0   2   \n",
      "44   0   0   0   0   1   2   1   0   2   0  ...   2   2   0   2   2   0   1   \n",
      "45   0   0   0   0   2   1   0   2   0   0  ...   2   1   1   2   0   0   1   \n",
      "46   0   0   2   0   2   1   1   1   2   0  ...   0   0   2   0   2   0   2   \n",
      "47   2   2   2   2   0   0   1   1   2   0  ...   2   2   2   0   1   1   1   \n",
      "48   1   0   2   1   0   1   1   0   0   1  ...   1   0   0   0   1   2   2   \n",
      "49   2   0   1   0   1   1   0   0   2   0  ...   2   0   0   2   0   2   1   \n",
      "\n",
      "    47  48  49  \n",
      "0    0   1   2  \n",
      "1    2   0   0  \n",
      "2    1   0   2  \n",
      "3    2   2   0  \n",
      "4    0   2   2  \n",
      "5    1   2   0  \n",
      "6    1   0   0  \n",
      "7    1   0   2  \n",
      "8    0   2   2  \n",
      "9    1   0   0  \n",
      "10   0   0   2  \n",
      "11   1   2   1  \n",
      "12   0   0   0  \n",
      "13   0   2   1  \n",
      "14   0   1   0  \n",
      "15   0   0   2  \n",
      "16   0   2   2  \n",
      "17   0   2   0  \n",
      "18   2   2   2  \n",
      "19   0   1   2  \n",
      "20   0   0   1  \n",
      "21   2   1   2  \n",
      "22   0   0   1  \n",
      "23   1   1   0  \n",
      "24   1   1   0  \n",
      "25   0   2   1  \n",
      "26   1   0   2  \n",
      "27   0   2   1  \n",
      "28   2   0   2  \n",
      "29   2   0   0  \n",
      "30   1   0   0  \n",
      "31   0   1   2  \n",
      "32   0   2   0  \n",
      "33   0   0   1  \n",
      "34   0   0   2  \n",
      "35   2   0   0  \n",
      "36   0   0   0  \n",
      "37   0   0   2  \n",
      "38   0   2   2  \n",
      "39   2   1   0  \n",
      "40   0   2   2  \n",
      "41   2   1   1  \n",
      "42   1   1   0  \n",
      "43   1   0   0  \n",
      "44   0   2   1  \n",
      "45   2   2   0  \n",
      "46   0   0   0  \n",
      "47   1   2   0  \n",
      "48   0   0   0  \n",
      "49   1   0   0  \n",
      "\n",
      "[50 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set n\n",
    "n = 50\n",
    "\n",
    "# Generate the random values with specified proportions\n",
    "values = np.random.permutation(\n",
    "    np.concatenate([\n",
    "        np.full(int(n * n * 0.5), 0),  # 50% 0's\n",
    "        np.full(int(n * n * 0.25), 1), # 25% 1's\n",
    "        np.full(int(n * n * 0.25), 2)  # 25% 2's\n",
    "    ])\n",
    ")\n",
    "\n",
    "# Reshape the values into an n x n matrix\n",
    "R = values.reshape(n, n)\n",
    "\n",
    "# Convert the matrix into a DataFrame\n",
    "df = pd.DataFrame(R)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nP6M8hfrxWUJ"
   },
   "source": [
    "* Randomly punch holes (i.e. `NA`) values in this matrix so that an each entry is missing with probability 30%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ffLrQxVTydX9",
    "outputId": "971f187e-4642-4ae7-d01e-4629b165e40d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2    3    4    5    6    7    8    9   ...   40   41   42   43  \\\n",
      "0   0.0  NaN  NaN  0.0  NaN  2.0  2.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  2.0   \n",
      "1   0.0  1.0  NaN  2.0  NaN  2.0  0.0  0.0  2.0  NaN  ...  0.0  1.0  1.0  0.0   \n",
      "2   1.0  0.0  1.0  0.0  2.0  1.0  0.0  NaN  2.0  1.0  ...  0.0  1.0  1.0  NaN   \n",
      "3   NaN  0.0  2.0  NaN  0.0  NaN  NaN  NaN  NaN  0.0  ...  2.0  0.0  NaN  2.0   \n",
      "4   0.0  NaN  1.0  NaN  0.0  0.0  0.0  1.0  NaN  0.0  ...  0.0  0.0  0.0  NaN   \n",
      "5   0.0  NaN  NaN  NaN  NaN  0.0  0.0  NaN  1.0  0.0  ...  1.0  0.0  0.0  NaN   \n",
      "6   1.0  2.0  1.0  0.0  2.0  0.0  0.0  NaN  NaN  0.0  ...  NaN  0.0  2.0  NaN   \n",
      "7   1.0  0.0  1.0  0.0  0.0  NaN  2.0  2.0  NaN  2.0  ...  0.0  NaN  2.0  2.0   \n",
      "8   1.0  NaN  1.0  2.0  NaN  0.0  NaN  0.0  1.0  2.0  ...  NaN  0.0  NaN  0.0   \n",
      "9   0.0  NaN  0.0  2.0  NaN  2.0  2.0  NaN  2.0  1.0  ...  0.0  NaN  0.0  NaN   \n",
      "10  NaN  0.0  2.0  NaN  0.0  0.0  NaN  0.0  NaN  NaN  ...  0.0  1.0  0.0  2.0   \n",
      "11  2.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  1.0  0.0  ...  0.0  1.0  2.0  NaN   \n",
      "12  NaN  2.0  0.0  NaN  2.0  0.0  NaN  0.0  0.0  0.0  ...  1.0  0.0  2.0  1.0   \n",
      "13  0.0  1.0  2.0  0.0  1.0  0.0  1.0  2.0  0.0  NaN  ...  2.0  0.0  0.0  0.0   \n",
      "14  1.0  1.0  NaN  2.0  1.0  0.0  2.0  0.0  2.0  0.0  ...  1.0  1.0  NaN  1.0   \n",
      "15  0.0  1.0  1.0  1.0  NaN  NaN  1.0  0.0  2.0  2.0  ...  NaN  1.0  2.0  1.0   \n",
      "16  0.0  0.0  0.0  NaN  0.0  1.0  NaN  0.0  1.0  0.0  ...  2.0  1.0  1.0  0.0   \n",
      "17  NaN  NaN  0.0  0.0  0.0  1.0  1.0  NaN  1.0  2.0  ...  NaN  2.0  1.0  NaN   \n",
      "18  1.0  1.0  0.0  1.0  0.0  0.0  0.0  NaN  0.0  2.0  ...  NaN  NaN  0.0  NaN   \n",
      "19  2.0  1.0  0.0  NaN  1.0  2.0  2.0  2.0  NaN  NaN  ...  NaN  0.0  1.0  2.0   \n",
      "20  2.0  NaN  NaN  0.0  0.0  0.0  2.0  NaN  NaN  NaN  ...  0.0  1.0  0.0  0.0   \n",
      "21  1.0  0.0  0.0  1.0  NaN  2.0  1.0  0.0  0.0  NaN  ...  NaN  0.0  NaN  NaN   \n",
      "22  NaN  0.0  0.0  NaN  1.0  NaN  0.0  1.0  1.0  0.0  ...  0.0  NaN  NaN  NaN   \n",
      "23  0.0  2.0  1.0  2.0  NaN  2.0  1.0  NaN  0.0  0.0  ...  1.0  0.0  2.0  2.0   \n",
      "24  1.0  0.0  0.0  NaN  0.0  2.0  NaN  0.0  2.0  2.0  ...  2.0  0.0  2.0  NaN   \n",
      "25  0.0  1.0  0.0  0.0  2.0  0.0  2.0  1.0  NaN  0.0  ...  0.0  2.0  0.0  0.0   \n",
      "26  0.0  0.0  2.0  1.0  0.0  NaN  NaN  NaN  NaN  2.0  ...  NaN  2.0  NaN  0.0   \n",
      "27  NaN  2.0  1.0  1.0  0.0  NaN  0.0  0.0  NaN  1.0  ...  NaN  NaN  NaN  0.0   \n",
      "28  0.0  NaN  0.0  NaN  NaN  NaN  0.0  0.0  1.0  2.0  ...  NaN  1.0  NaN  0.0   \n",
      "29  NaN  NaN  0.0  NaN  0.0  NaN  0.0  1.0  1.0  2.0  ...  NaN  0.0  NaN  NaN   \n",
      "30  0.0  0.0  NaN  0.0  NaN  2.0  0.0  0.0  NaN  2.0  ...  2.0  1.0  NaN  NaN   \n",
      "31  1.0  2.0  NaN  0.0  NaN  NaN  NaN  0.0  2.0  2.0  ...  1.0  NaN  0.0  0.0   \n",
      "32  1.0  NaN  0.0  NaN  NaN  0.0  1.0  NaN  0.0  0.0  ...  0.0  2.0  1.0  0.0   \n",
      "33  NaN  0.0  1.0  NaN  NaN  1.0  0.0  0.0  NaN  NaN  ...  NaN  1.0  NaN  NaN   \n",
      "34  0.0  2.0  NaN  NaN  0.0  0.0  0.0  2.0  0.0  NaN  ...  0.0  0.0  0.0  0.0   \n",
      "35  NaN  0.0  NaN  NaN  0.0  NaN  0.0  1.0  1.0  0.0  ...  1.0  2.0  2.0  NaN   \n",
      "36  0.0  2.0  NaN  NaN  0.0  0.0  0.0  0.0  NaN  2.0  ...  0.0  1.0  1.0  NaN   \n",
      "37  0.0  1.0  0.0  2.0  NaN  0.0  1.0  0.0  0.0  NaN  ...  NaN  NaN  1.0  NaN   \n",
      "38  2.0  0.0  1.0  NaN  NaN  1.0  2.0  1.0  1.0  0.0  ...  NaN  NaN  1.0  NaN   \n",
      "39  0.0  2.0  0.0  2.0  0.0  0.0  2.0  2.0  0.0  0.0  ...  2.0  0.0  0.0  NaN   \n",
      "40  0.0  2.0  NaN  NaN  2.0  2.0  0.0  2.0  NaN  NaN  ...  0.0  2.0  0.0  NaN   \n",
      "41  NaN  1.0  NaN  1.0  0.0  0.0  0.0  0.0  0.0  NaN  ...  NaN  2.0  0.0  1.0   \n",
      "42  0.0  0.0  NaN  1.0  0.0  0.0  0.0  0.0  1.0  2.0  ...  NaN  2.0  NaN  NaN   \n",
      "43  0.0  NaN  2.0  0.0  2.0  2.0  2.0  NaN  2.0  1.0  ...  NaN  NaN  1.0  0.0   \n",
      "44  0.0  0.0  NaN  0.0  1.0  2.0  NaN  NaN  NaN  0.0  ...  2.0  NaN  0.0  2.0   \n",
      "45  0.0  NaN  NaN  0.0  NaN  NaN  NaN  2.0  0.0  0.0  ...  2.0  1.0  1.0  2.0   \n",
      "46  NaN  0.0  2.0  NaN  2.0  NaN  1.0  1.0  2.0  0.0  ...  0.0  0.0  2.0  0.0   \n",
      "47  2.0  NaN  2.0  2.0  NaN  0.0  1.0  NaN  2.0  0.0  ...  2.0  2.0  2.0  0.0   \n",
      "48  1.0  0.0  2.0  1.0  0.0  NaN  1.0  NaN  0.0  1.0  ...  1.0  0.0  NaN  0.0   \n",
      "49  NaN  NaN  1.0  0.0  NaN  NaN  0.0  0.0  NaN  0.0  ...  2.0  NaN  0.0  NaN   \n",
      "\n",
      "     44   45   46   47   48   49  \n",
      "0   2.0  NaN  NaN  0.0  NaN  2.0  \n",
      "1   1.0  NaN  NaN  2.0  NaN  0.0  \n",
      "2   2.0  0.0  0.0  NaN  0.0  2.0  \n",
      "3   0.0  0.0  0.0  NaN  2.0  NaN  \n",
      "4   1.0  0.0  0.0  0.0  2.0  2.0  \n",
      "5   0.0  NaN  0.0  1.0  NaN  0.0  \n",
      "6   2.0  2.0  NaN  1.0  0.0  NaN  \n",
      "7   0.0  NaN  NaN  NaN  NaN  2.0  \n",
      "8   NaN  0.0  1.0  0.0  2.0  NaN  \n",
      "9   NaN  NaN  0.0  1.0  0.0  0.0  \n",
      "10  NaN  NaN  0.0  NaN  0.0  2.0  \n",
      "11  1.0  1.0  1.0  1.0  NaN  1.0  \n",
      "12  1.0  NaN  NaN  0.0  NaN  NaN  \n",
      "13  1.0  0.0  0.0  NaN  2.0  1.0  \n",
      "14  0.0  0.0  1.0  0.0  1.0  0.0  \n",
      "15  1.0  NaN  2.0  0.0  0.0  2.0  \n",
      "16  0.0  NaN  0.0  0.0  2.0  2.0  \n",
      "17  2.0  0.0  1.0  NaN  2.0  0.0  \n",
      "18  0.0  1.0  0.0  NaN  2.0  NaN  \n",
      "19  2.0  0.0  2.0  NaN  1.0  2.0  \n",
      "20  1.0  NaN  2.0  NaN  0.0  1.0  \n",
      "21  0.0  0.0  1.0  2.0  NaN  NaN  \n",
      "22  NaN  NaN  0.0  NaN  0.0  NaN  \n",
      "23  2.0  2.0  NaN  NaN  1.0  NaN  \n",
      "24  0.0  2.0  0.0  1.0  1.0  0.0  \n",
      "25  0.0  1.0  NaN  0.0  2.0  1.0  \n",
      "26  NaN  NaN  0.0  NaN  0.0  NaN  \n",
      "27  0.0  2.0  0.0  0.0  2.0  1.0  \n",
      "28  NaN  1.0  1.0  NaN  0.0  2.0  \n",
      "29  0.0  NaN  1.0  2.0  0.0  0.0  \n",
      "30  NaN  0.0  0.0  1.0  0.0  0.0  \n",
      "31  0.0  1.0  0.0  0.0  1.0  2.0  \n",
      "32  1.0  0.0  0.0  0.0  2.0  0.0  \n",
      "33  0.0  0.0  NaN  0.0  0.0  1.0  \n",
      "34  NaN  1.0  0.0  0.0  NaN  NaN  \n",
      "35  0.0  1.0  NaN  2.0  0.0  0.0  \n",
      "36  NaN  0.0  2.0  0.0  0.0  NaN  \n",
      "37  NaN  NaN  0.0  0.0  0.0  NaN  \n",
      "38  0.0  NaN  0.0  0.0  2.0  2.0  \n",
      "39  0.0  NaN  0.0  NaN  NaN  NaN  \n",
      "40  NaN  0.0  NaN  0.0  NaN  NaN  \n",
      "41  0.0  NaN  NaN  NaN  NaN  1.0  \n",
      "42  0.0  0.0  1.0  NaN  1.0  0.0  \n",
      "43  2.0  NaN  2.0  1.0  0.0  0.0  \n",
      "44  NaN  0.0  1.0  0.0  2.0  1.0  \n",
      "45  0.0  0.0  NaN  NaN  NaN  0.0  \n",
      "46  2.0  0.0  2.0  0.0  0.0  0.0  \n",
      "47  NaN  NaN  NaN  1.0  NaN  NaN  \n",
      "48  1.0  2.0  NaN  0.0  NaN  0.0  \n",
      "49  0.0  2.0  1.0  1.0  0.0  0.0  \n",
      "\n",
      "[50 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert to float to allow NaN\n",
    "df = df.astype(float)\n",
    "\n",
    "# Randomly punch holes with 30% probability\n",
    "mask = np.random.choice([True, False], size=df.shape, p=[0.3, 0.7])\n",
    "df[mask] = np.nan\n",
    "\n",
    "# View the resulting DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set matrix dimensions and proportions\n",
    "n = 50\n",
    "values = np.random.permutation(\n",
    "    np.concatenate([\n",
    "        np.full(int(n * n * 0.5), 0),  # 50% 0's\n",
    "        np.full(int(n * n * 0.25), 1), # 25% 1's\n",
    "        np.full(int(n * n * 0.25), 2)  # 25% 2's\n",
    "    ])\n",
    ")\n",
    "\n",
    "# Reshape the matrix\n",
    "#R = values.reshape(n, n)\n",
    "\n",
    "len(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LaCZ-_c4xPxp",
    "outputId": "198e2ee0-f845-4ec5-ae0d-10fe2ebc0aae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2    3    4    5    6    7    8    9   ...   40   41   42   43  \\\n",
      "0   2.0  NaN  NaN  1.0  2.0  2.0  0.0  0.0  NaN  0.0  ...  0.0  2.0  NaN  NaN   \n",
      "1   NaN  NaN  1.0  0.0  0.0  0.0  NaN  0.0  2.0  0.0  ...  0.0  NaN  NaN  NaN   \n",
      "2   0.0  NaN  1.0  NaN  0.0  0.0  0.0  1.0  1.0  2.0  ...  0.0  2.0  1.0  0.0   \n",
      "3   1.0  2.0  0.0  1.0  0.0  2.0  0.0  0.0  NaN  0.0  ...  NaN  0.0  1.0  0.0   \n",
      "4   NaN  1.0  1.0  NaN  1.0  NaN  NaN  NaN  NaN  1.0  ...  2.0  1.0  0.0  2.0   \n",
      "5   1.0  0.0  1.0  1.0  NaN  1.0  0.0  0.0  2.0  0.0  ...  0.0  0.0  NaN  0.0   \n",
      "6   2.0  NaN  0.0  NaN  2.0  0.0  1.0  NaN  NaN  NaN  ...  0.0  1.0  0.0  0.0   \n",
      "7   2.0  NaN  0.0  1.0  2.0  0.0  1.0  0.0  NaN  1.0  ...  1.0  2.0  2.0  0.0   \n",
      "8   0.0  1.0  2.0  0.0  NaN  1.0  0.0  1.0  2.0  NaN  ...  NaN  0.0  NaN  0.0   \n",
      "9   2.0  NaN  0.0  1.0  0.0  0.0  NaN  0.0  NaN  0.0  ...  0.0  1.0  0.0  0.0   \n",
      "10  0.0  NaN  0.0  NaN  0.0  NaN  NaN  NaN  0.0  2.0  ...  NaN  NaN  NaN  0.0   \n",
      "11  2.0  0.0  0.0  2.0  2.0  1.0  0.0  NaN  NaN  NaN  ...  0.0  NaN  2.0  1.0   \n",
      "12  NaN  0.0  2.0  2.0  NaN  2.0  0.0  0.0  2.0  1.0  ...  0.0  2.0  0.0  0.0   \n",
      "13  1.0  2.0  0.0  NaN  0.0  0.0  NaN  1.0  0.0  2.0  ...  NaN  0.0  NaN  0.0   \n",
      "14  2.0  NaN  1.0  NaN  1.0  NaN  0.0  2.0  NaN  NaN  ...  1.0  1.0  0.0  NaN   \n",
      "15  0.0  0.0  0.0  0.0  0.0  0.0  2.0  NaN  0.0  1.0  ...  0.0  NaN  0.0  NaN   \n",
      "16  2.0  0.0  0.0  NaN  0.0  0.0  0.0  1.0  0.0  NaN  ...  NaN  NaN  2.0  NaN   \n",
      "17  NaN  0.0  2.0  0.0  NaN  2.0  NaN  1.0  NaN  NaN  ...  NaN  1.0  2.0  1.0   \n",
      "18  NaN  NaN  NaN  1.0  0.0  1.0  NaN  0.0  1.0  0.0  ...  0.0  1.0  1.0  1.0   \n",
      "19  0.0  0.0  2.0  1.0  NaN  2.0  0.0  0.0  NaN  NaN  ...  0.0  0.0  NaN  0.0   \n",
      "20  0.0  NaN  NaN  2.0  2.0  0.0  0.0  1.0  2.0  2.0  ...  1.0  2.0  0.0  0.0   \n",
      "21  NaN  NaN  1.0  1.0  NaN  1.0  1.0  NaN  NaN  2.0  ...  0.0  1.0  0.0  0.0   \n",
      "22  1.0  0.0  0.0  0.0  0.0  NaN  0.0  0.0  NaN  0.0  ...  NaN  NaN  2.0  2.0   \n",
      "23  1.0  2.0  NaN  0.0  0.0  NaN  1.0  0.0  0.0  NaN  ...  NaN  NaN  1.0  NaN   \n",
      "24  2.0  NaN  NaN  0.0  2.0  2.0  NaN  2.0  NaN  1.0  ...  NaN  NaN  NaN  1.0   \n",
      "25  2.0  0.0  NaN  0.0  NaN  NaN  NaN  2.0  2.0  NaN  ...  NaN  0.0  NaN  0.0   \n",
      "26  2.0  1.0  0.0  NaN  2.0  0.0  0.0  1.0  1.0  0.0  ...  1.0  NaN  0.0  0.0   \n",
      "27  0.0  NaN  NaN  0.0  0.0  NaN  NaN  1.0  2.0  NaN  ...  NaN  NaN  2.0  NaN   \n",
      "28  1.0  NaN  2.0  NaN  NaN  NaN  0.0  0.0  NaN  1.0  ...  0.0  2.0  0.0  1.0   \n",
      "29  1.0  0.0  1.0  NaN  2.0  1.0  0.0  0.0  1.0  2.0  ...  NaN  NaN  0.0  0.0   \n",
      "30  NaN  1.0  NaN  1.0  2.0  2.0  NaN  2.0  0.0  NaN  ...  NaN  NaN  1.0  2.0   \n",
      "31  NaN  NaN  0.0  NaN  NaN  NaN  2.0  0.0  0.0  2.0  ...  2.0  0.0  0.0  NaN   \n",
      "32  NaN  0.0  NaN  1.0  1.0  2.0  0.0  0.0  NaN  0.0  ...  2.0  1.0  2.0  1.0   \n",
      "33  0.0  NaN  NaN  0.0  0.0  1.0  NaN  1.0  0.0  0.0  ...  0.0  0.0  2.0  0.0   \n",
      "34  0.0  1.0  NaN  NaN  NaN  2.0  2.0  1.0  NaN  1.0  ...  0.0  1.0  0.0  0.0   \n",
      "35  0.0  2.0  2.0  NaN  NaN  0.0  0.0  2.0  NaN  0.0  ...  1.0  0.0  1.0  2.0   \n",
      "36  NaN  2.0  1.0  NaN  2.0  1.0  0.0  0.0  NaN  0.0  ...  NaN  2.0  2.0  2.0   \n",
      "37  NaN  2.0  0.0  NaN  0.0  2.0  2.0  1.0  0.0  0.0  ...  NaN  0.0  0.0  NaN   \n",
      "38  0.0  1.0  1.0  NaN  NaN  0.0  NaN  NaN  1.0  0.0  ...  1.0  NaN  0.0  0.0   \n",
      "39  NaN  2.0  2.0  0.0  0.0  NaN  2.0  1.0  0.0  0.0  ...  NaN  1.0  NaN  NaN   \n",
      "40  1.0  1.0  2.0  NaN  1.0  2.0  0.0  1.0  0.0  0.0  ...  0.0  0.0  1.0  1.0   \n",
      "41  NaN  0.0  1.0  1.0  NaN  NaN  0.0  0.0  NaN  0.0  ...  0.0  1.0  0.0  2.0   \n",
      "42  0.0  1.0  0.0  0.0  1.0  NaN  2.0  NaN  NaN  0.0  ...  NaN  NaN  0.0  NaN   \n",
      "43  NaN  1.0  1.0  0.0  NaN  2.0  0.0  NaN  0.0  0.0  ...  2.0  0.0  1.0  0.0   \n",
      "44  1.0  1.0  0.0  0.0  0.0  NaN  NaN  0.0  NaN  2.0  ...  1.0  2.0  0.0  0.0   \n",
      "45  2.0  0.0  1.0  0.0  2.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0  NaN   \n",
      "46  2.0  0.0  NaN  NaN  0.0  1.0  2.0  NaN  0.0  0.0  ...  2.0  2.0  2.0  0.0   \n",
      "47  NaN  1.0  1.0  1.0  0.0  NaN  2.0  0.0  NaN  0.0  ...  1.0  NaN  0.0  NaN   \n",
      "48  0.0  NaN  0.0  1.0  0.0  NaN  2.0  2.0  0.0  NaN  ...  0.0  2.0  NaN  0.0   \n",
      "49  NaN  0.0  1.0  0.0  1.0  NaN  1.0  NaN  NaN  0.0  ...  NaN  NaN  NaN  2.0   \n",
      "\n",
      "     44   45   46   47   48   49  \n",
      "0   0.0  NaN  0.0  0.0  0.0  NaN  \n",
      "1   NaN  NaN  1.0  2.0  NaN  0.0  \n",
      "2   NaN  NaN  0.0  2.0  NaN  1.0  \n",
      "3   NaN  1.0  NaN  NaN  2.0  1.0  \n",
      "4   1.0  0.0  1.0  0.0  1.0  2.0  \n",
      "5   NaN  1.0  2.0  0.0  1.0  NaN  \n",
      "6   1.0  0.0  0.0  1.0  NaN  0.0  \n",
      "7   1.0  0.0  0.0  NaN  1.0  NaN  \n",
      "8   NaN  0.0  NaN  2.0  0.0  0.0  \n",
      "9   NaN  2.0  0.0  NaN  0.0  0.0  \n",
      "10  NaN  2.0  NaN  NaN  0.0  2.0  \n",
      "11  2.0  NaN  0.0  0.0  NaN  NaN  \n",
      "12  NaN  1.0  2.0  NaN  0.0  NaN  \n",
      "13  0.0  2.0  0.0  0.0  NaN  NaN  \n",
      "14  0.0  NaN  NaN  0.0  0.0  NaN  \n",
      "15  NaN  NaN  1.0  2.0  2.0  0.0  \n",
      "16  0.0  0.0  2.0  NaN  NaN  NaN  \n",
      "17  1.0  2.0  2.0  1.0  0.0  NaN  \n",
      "18  0.0  0.0  2.0  NaN  NaN  0.0  \n",
      "19  NaN  NaN  0.0  NaN  1.0  1.0  \n",
      "20  1.0  NaN  2.0  NaN  0.0  1.0  \n",
      "21  1.0  2.0  0.0  0.0  NaN  NaN  \n",
      "22  0.0  2.0  NaN  NaN  1.0  0.0  \n",
      "23  NaN  NaN  1.0  2.0  2.0  NaN  \n",
      "24  2.0  NaN  0.0  1.0  NaN  NaN  \n",
      "25  NaN  1.0  0.0  1.0  NaN  1.0  \n",
      "26  NaN  NaN  0.0  2.0  2.0  2.0  \n",
      "27  2.0  NaN  NaN  NaN  1.0  0.0  \n",
      "28  0.0  NaN  0.0  1.0  2.0  NaN  \n",
      "29  0.0  1.0  NaN  NaN  NaN  NaN  \n",
      "30  0.0  0.0  NaN  NaN  NaN  0.0  \n",
      "31  1.0  1.0  NaN  2.0  NaN  0.0  \n",
      "32  2.0  0.0  0.0  2.0  2.0  0.0  \n",
      "33  0.0  1.0  NaN  0.0  0.0  NaN  \n",
      "34  0.0  0.0  2.0  NaN  2.0  2.0  \n",
      "35  1.0  NaN  0.0  NaN  0.0  NaN  \n",
      "36  2.0  2.0  NaN  0.0  NaN  2.0  \n",
      "37  1.0  0.0  NaN  0.0  0.0  0.0  \n",
      "38  2.0  2.0  0.0  1.0  1.0  0.0  \n",
      "39  NaN  NaN  2.0  NaN  NaN  1.0  \n",
      "40  0.0  NaN  0.0  0.0  2.0  NaN  \n",
      "41  0.0  0.0  NaN  0.0  2.0  0.0  \n",
      "42  0.0  1.0  1.0  NaN  0.0  NaN  \n",
      "43  2.0  2.0  2.0  1.0  2.0  0.0  \n",
      "44  NaN  0.0  NaN  0.0  1.0  0.0  \n",
      "45  0.0  0.0  NaN  NaN  0.0  2.0  \n",
      "46  0.0  NaN  0.0  1.0  NaN  NaN  \n",
      "47  0.0  NaN  0.0  0.0  1.0  NaN  \n",
      "48  2.0  1.0  NaN  0.0  NaN  NaN  \n",
      "49  1.0  2.0  0.0  NaN  NaN  0.0  \n",
      "\n",
      "[50 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set matrix dimensions and proportions\n",
    "n = 50\n",
    "values = np.random.permutation(\n",
    "    np.concatenate([\n",
    "        np.full(int(n * n * 0.5), 0),  # 50% 0's\n",
    "        np.full(int(n * n * 0.25), 1), # 25% 1's\n",
    "        np.full(int(n * n * 0.25), 2)  # 25% 2's\n",
    "    ])\n",
    ")\n",
    "\n",
    "# Reshape the matrix\n",
    "R = values.reshape(n, n)\n",
    "\n",
    "# Create a mask for punching holes with a 30% probability\n",
    "random_holes = np.random.choice([True, False], size=(n, n), p=[0.3, 0.7])\n",
    "\n",
    "# Assign NaN to the corresponding positions\n",
    "R = R.astype(float)  # Convert to float to support NaN\n",
    "R[random_holes] = np.nan\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(R)\n",
    "\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trL0Ltu4yp9m"
   },
   "source": [
    "* Sort the rows in matrix `R` by the largest row sum to lowest. Be careful about the NA's!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QGPEL3Ba1ana",
    "outputId": "5fed490c-5567-42dd-f607-495500c373ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan,  0.,  2., ...,  1.,  0., nan],\n",
       "       [nan,  1.,  1., ...,  1.,  2.,  0.],\n",
       "       [nan,  0., nan, ...,  2.,  2.,  0.],\n",
       "       ...,\n",
       "       [ 2., nan,  0., ..., nan,  0.,  0.],\n",
       "       [ 2.,  0., nan, ...,  1., nan,  1.],\n",
       "       [ 2.,  0.,  0., ..., nan, nan, nan]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compute the row sums while ignoring nan values\n",
    "row_sums = np.nansum(R, axis = 1)\n",
    "\n",
    "#Get the order of the indices that would sort the matrix\n",
    "sorted_indices = np.argsort(row_sums)\n",
    "\n",
    "#np.argsort(-row_sums) reverses the order so you don't have to wha twas done below.\n",
    "\n",
    "#Use the indices to sort the matrix and use the slice notation to reverse it to descending order.\n",
    "sorted_R = R[sorted_indices][::-1]\n",
    "\n",
    "\n",
    "sorted_R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1T_tkkym9FIP"
   },
   "source": [
    "* Python does not have an apply function. Instead use the nanstd function in numpy to calculate the standard devation of each column. Print them and combine then into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8569883696666746, 0.7796775957738549, 0.7663273567663703, 0.6547602137424051, 0.8854098583616237, 0.8569883696666746, 0.8548156974127289, 0.7333512639012868, 0.8526566246830624, 0.8123867916017434, 0.8971610553204331, 0.8870956969291443, 0.8609445168157461, 0.7793206786821498, 0.7870051858976266, 0.7959954870644662, 0.8650259511678084, 0.8564835163859432, 0.7247430753394787, 0.8789148704402314, 0.7565186709392627, 0.8050858744917355, 0.7951240294584374, 0.8086898285216191, 0.8397710518356379, 0.8439325934114775, 0.793509094913686, 0.834296963511285, 0.8124038404635959, 0.8717797887081348, 0.8748897637790902, 0.7431203829658118, 0.8833308765689106, 0.82915619758885, 0.6976281474679596, 0.8299933065325822, 0.8534606386520674, 0.8447886244908864, 0.8542809364414886, 0.8588680463189059, 0.7473912964438374, 0.8177316926151672, 0.8408708057194978, 0.7898183349298625, 0.8050858744917355, 0.8425917976695477, 0.8650259511678083, 0.8312321759177501, 0.8425917976695477, 0.8057463065895121]\n",
      "[0.8406827016444971, 0.8042692268752138, 0.7548237861496726, 0.7789619230571372, 0.7667790675964982, 0.8147947848043934, 0.7916658657230707, 0.8660254037844386, 0.7687785169756406, 0.7435057058415332, 0.8498025724077091, 0.9117647058823529, 0.9326988577290942, 0.9131223741405675, 0.7949493345141213, 0.8589323557876055, 0.7111421833886646, 0.7613092911128131, 0.7581815759513214, 0.7551419297238467, 0.8559031717046192, 0.7071067811865476, 0.8442764761416073, 0.7948810838735565, 0.8265564664839913, 0.7759128922285868, 0.8071991634090854, 0.8858781088734572, 0.8620067027323834, 0.855235974119758, 0.9123280382981347, 0.8173457715690274, 0.8807546383057459, 0.7787177820513957, 0.8748897637790901, 0.858501148195672, 0.8342969635112851, 0.6418563290290766, 0.7310507928372617, 0.7715802465185059, 0.8599952539024236, 0.803817071015856, 0.8076779989575054, 0.858878678176627, 0.8585011481956719, 0.8096679352535526, 0.9030099651970508, 0.742636415046538, 0.8589323557876055, 0.9180269263480239]\n"
     ]
    }
   ],
   "source": [
    "#Compute row-wise and column-wise standard deviations\n",
    "row_std = np.nanstd(R,axis = 1)\n",
    "col_std = np.nanstd(R, axis = 0)\n",
    "\n",
    "#Map the results into a dictionary\n",
    "results = {'row_std': row_std.tolist(), \"col_std\" : col_std.tolist()}\n",
    "\n",
    "print(results['col_std'])\n",
    "print(results['row_std'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* combine the results from the previous cell into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZT3Gzrcm5pR2",
    "outputId": "89a7707e-c0e9-45be-cf24-8d7193609bae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_std</th>\n",
       "      <th>col_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.840683</td>\n",
       "      <td>0.856988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.804269</td>\n",
       "      <td>0.779678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.754824</td>\n",
       "      <td>0.766327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.778962</td>\n",
       "      <td>0.654760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.766779</td>\n",
       "      <td>0.885410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.814795</td>\n",
       "      <td>0.856988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.791666</td>\n",
       "      <td>0.854816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.733351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.768779</td>\n",
       "      <td>0.852657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.743506</td>\n",
       "      <td>0.812387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.849803</td>\n",
       "      <td>0.897161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.887096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.932699</td>\n",
       "      <td>0.860945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.913122</td>\n",
       "      <td>0.779321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.794949</td>\n",
       "      <td>0.787005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.858932</td>\n",
       "      <td>0.795995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.711142</td>\n",
       "      <td>0.865026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.761309</td>\n",
       "      <td>0.856484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.758182</td>\n",
       "      <td>0.724743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.755142</td>\n",
       "      <td>0.878915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.855903</td>\n",
       "      <td>0.756519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.805086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.844276</td>\n",
       "      <td>0.795124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.794881</td>\n",
       "      <td>0.808690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.826556</td>\n",
       "      <td>0.839771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.775913</td>\n",
       "      <td>0.843933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.807199</td>\n",
       "      <td>0.793509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.885878</td>\n",
       "      <td>0.834297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.862007</td>\n",
       "      <td>0.812404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.855236</td>\n",
       "      <td>0.871780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.912328</td>\n",
       "      <td>0.874890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.817346</td>\n",
       "      <td>0.743120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.880755</td>\n",
       "      <td>0.883331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.778718</td>\n",
       "      <td>0.829156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.874890</td>\n",
       "      <td>0.697628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.858501</td>\n",
       "      <td>0.829993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.834297</td>\n",
       "      <td>0.853461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.641856</td>\n",
       "      <td>0.844789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.731051</td>\n",
       "      <td>0.854281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.771580</td>\n",
       "      <td>0.858868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.859995</td>\n",
       "      <td>0.747391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.803817</td>\n",
       "      <td>0.817732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.807678</td>\n",
       "      <td>0.840871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.858879</td>\n",
       "      <td>0.789818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.858501</td>\n",
       "      <td>0.805086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.809668</td>\n",
       "      <td>0.842592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.903010</td>\n",
       "      <td>0.865026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.742636</td>\n",
       "      <td>0.831232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.858932</td>\n",
       "      <td>0.842592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.918027</td>\n",
       "      <td>0.805746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     row_std   col_std\n",
       "0   0.840683  0.856988\n",
       "1   0.804269  0.779678\n",
       "2   0.754824  0.766327\n",
       "3   0.778962  0.654760\n",
       "4   0.766779  0.885410\n",
       "5   0.814795  0.856988\n",
       "6   0.791666  0.854816\n",
       "7   0.866025  0.733351\n",
       "8   0.768779  0.852657\n",
       "9   0.743506  0.812387\n",
       "10  0.849803  0.897161\n",
       "11  0.911765  0.887096\n",
       "12  0.932699  0.860945\n",
       "13  0.913122  0.779321\n",
       "14  0.794949  0.787005\n",
       "15  0.858932  0.795995\n",
       "16  0.711142  0.865026\n",
       "17  0.761309  0.856484\n",
       "18  0.758182  0.724743\n",
       "19  0.755142  0.878915\n",
       "20  0.855903  0.756519\n",
       "21  0.707107  0.805086\n",
       "22  0.844276  0.795124\n",
       "23  0.794881  0.808690\n",
       "24  0.826556  0.839771\n",
       "25  0.775913  0.843933\n",
       "26  0.807199  0.793509\n",
       "27  0.885878  0.834297\n",
       "28  0.862007  0.812404\n",
       "29  0.855236  0.871780\n",
       "30  0.912328  0.874890\n",
       "31  0.817346  0.743120\n",
       "32  0.880755  0.883331\n",
       "33  0.778718  0.829156\n",
       "34  0.874890  0.697628\n",
       "35  0.858501  0.829993\n",
       "36  0.834297  0.853461\n",
       "37  0.641856  0.844789\n",
       "38  0.731051  0.854281\n",
       "39  0.771580  0.858868\n",
       "40  0.859995  0.747391\n",
       "41  0.803817  0.817732\n",
       "42  0.807678  0.840871\n",
       "43  0.858879  0.789818\n",
       "44  0.858501  0.805086\n",
       "45  0.809668  0.842592\n",
       "46  0.903010  0.865026\n",
       "47  0.742636  0.831232\n",
       "48  0.858932  0.842592\n",
       "49  0.918027  0.805746"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-A7Cfa98DDg"
   },
   "source": [
    "* Use the Pandas apply function to compute a vector whose entries are the count of entries that are 1 or 2 in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "54XfftmJ77oY",
    "outputId": "8baa21e3-58dc-4348-d205-288750a36dd2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     21\n",
       "1     18\n",
       "2     22\n",
       "3     16\n",
       "4     17\n",
       "5     21\n",
       "6     14\n",
       "7     19\n",
       "8     12\n",
       "9     15\n",
       "10    16\n",
       "11    14\n",
       "12    23\n",
       "13    16\n",
       "14    17\n",
       "15    19\n",
       "16    14\n",
       "17    18\n",
       "18    17\n",
       "19    23\n",
       "20    11\n",
       "21    18\n",
       "22    13\n",
       "23    13\n",
       "24    21\n",
       "25    15\n",
       "26    19\n",
       "27    15\n",
       "28    19\n",
       "29    15\n",
       "30    20\n",
       "31    18\n",
       "32    20\n",
       "33    21\n",
       "34    10\n",
       "35    13\n",
       "36    18\n",
       "37    19\n",
       "38    15\n",
       "39    13\n",
       "40    13\n",
       "41    21\n",
       "42    19\n",
       "43    14\n",
       "44    18\n",
       "45    19\n",
       "46    14\n",
       "47    16\n",
       "48    19\n",
       "49    12\n",
       "dtype: int64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results_1_or_2 = df.apply(lambda col : ((col == 1) | (col == 2)).sum())\n",
    "\n",
    "results_1_or_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YGsPbNYnGw7b"
   },
   "source": [
    "Since we just switched between Pandas dataframes and Numpy arrays. Here are some handy ways to check to see if you are working with a Pandas dataframe or a Numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XIaPkMlqHaN4",
    "outputId": "a1564ca8-68a0-4696-ac53-d7283a2bd919"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R is a NumPy array\n"
     ]
    }
   ],
   "source": [
    "# Check type directly\n",
    "if type(R) == pd.DataFrame:\n",
    "    print(\"R is a Pandas DataFrame\")\n",
    "\n",
    "if type(R) == np.ndarray:\n",
    "    print(\"R is a NumPy array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TbnwGrJzGAjI",
    "outputId": "54de6748-d7e4-420e-fb7e-3719496a1c90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy array\n"
     ]
    }
   ],
   "source": [
    "# isinstance(object, classinfo): This function checks if an object is an instance of a specified class or subclass.\n",
    "# function utilizing this function to check\n",
    "def check_type(R):\n",
    "    if isinstance(R, pd.DataFrame):\n",
    "        return \"Pandas DataFrame\"\n",
    "    elif isinstance(R, np.ndarray):\n",
    "        return \"NumPy array\"\n",
    "    else:\n",
    "        return \"Unknown type\"\n",
    "\n",
    "# Test the function\n",
    "print(check_type(R))  # Output: Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ys-3fJhOHrIq"
   },
   "source": [
    "* Create a list whose keys are the column number and values are the vector of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [1.0, 2.0, 1.0, 0.0, nan, nan, 0.0, nan, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, nan, nan, 2.0, 0.0, 0.0, nan, 2.0, 2.0, 0.0, nan, 2.0, nan, 1.0, 1.0, nan, 2.0, 1.0, nan, nan, 1.0, nan, 1.0, 0.0, 2.0, nan, nan, 0.0, 2.0, 0.0, nan, 1.0, 2.0], 1: [1.0, 2.0, nan, 2.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, nan, nan, nan, nan, nan, nan, 0.0, nan, nan, 2.0, nan, 2.0, 2.0, 1.0, nan, 0.0, nan, 0.0, nan, 1.0, 1.0, nan, 0.0, nan, 0.0, 1.0, 0.0, 2.0, nan, 0.0, nan, nan, nan, 2.0, nan, 2.0, 0.0, 0.0, 0.0, 2.0], 2: [1.0, 1.0, nan, nan, nan, 0.0, 2.0, 0.0, nan, nan, 0.0, nan, 0.0, nan, 0.0, 2.0, nan, 0.0, 2.0, 0.0, 0.0, 0.0, nan, 1.0, 0.0, 1.0, nan, nan, 2.0, 1.0, 1.0, 2.0, nan, 0.0, 1.0, nan, 0.0, 0.0, 0.0, nan, 0.0, 0.0, nan, 0.0, 2.0, 2.0, nan, 0.0, 2.0, 1.0], 3: [0.0, 2.0, 0.0, nan, 0.0, 0.0, nan, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 2.0, nan, 0.0, 0.0, 0.0, nan, nan, nan, 1.0, 2.0, 2.0, 1.0, nan, nan, nan, nan, 2.0, 0.0, 0.0, 0.0, 1.0, nan, 2.0, 2.0, nan, nan, 1.0, 0.0, 2.0, nan, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0], 4: [1.0, nan, nan, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, nan, 1.0, 1.0, nan, nan, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, nan, 1.0, 1.0, 1.0, nan, 2.0, nan, nan, 2.0, 2.0, nan, nan, nan, 0.0, nan, nan, nan, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, nan, 0.0, 1.0, 1.0], 5: [2.0, 2.0, 0.0, 2.0, 0.0, nan, 1.0, 1.0, nan, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, nan, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, nan, nan, 0.0, nan, 2.0, nan, nan, 0.0, 0.0, nan, 1.0, 0.0, 0.0, 0.0, 1.0, nan, 2.0, nan, 0.0, nan, 2.0, nan, 0.0, 2.0, nan, 0.0, 1.0, nan], 6: [0.0, nan, 0.0, nan, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, nan, 0.0, 1.0, nan, 0.0, nan, 0.0, 0.0, nan, nan, 2.0, 2.0, nan, 0.0, 0.0, 1.0, nan, 0.0, nan, nan, 1.0, 1.0, 1.0, nan, 0.0, nan, 0.0, 2.0, 0.0, nan, 2.0, 0.0, nan, 1.0, 1.0, nan, 0.0, nan, nan], 7: [0.0, 1.0, 0.0, nan, 1.0, 0.0, nan, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, nan, 0.0, nan, 0.0, 1.0, nan, nan, 0.0, nan, 1.0, nan, 1.0, nan, 1.0, 0.0, 0.0, 0.0, nan, 1.0, nan, nan, nan, 1.0, 0.0, 1.0, 0.0, nan, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0], 8: [0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, nan, nan, 0.0, 0.0, 0.0, nan, 0.0, 0.0, nan, 2.0, nan, 0.0, 2.0, 0.0, nan, nan, 2.0, 0.0, 2.0, 0.0, nan, 0.0, nan, nan, 0.0, 0.0, 0.0, 2.0, nan, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, nan, nan, 0.0], 9: [nan, 0.0, 0.0, 0.0, 0.0, nan, nan, 0.0, 1.0, 1.0, nan, 0.0, 2.0, 1.0, 2.0, 0.0, nan, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, nan, 0.0, 1.0, 2.0, nan, nan, 2.0, 0.0, 1.0, 2.0, nan, 1.0, 0.0, 0.0, nan, nan, nan, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0], 10: [2.0, nan, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, nan, 0.0, 1.0, 2.0, 0.0, 0.0, nan, nan, 1.0, nan, 0.0, nan, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, nan, 2.0, 0.0, 0.0, nan, 0.0, 1.0, 1.0, nan, 1.0, nan, 1.0, 2.0, 0.0, 0.0, 0.0, nan, 0.0, nan], 11: [0.0, nan, 2.0, 0.0, 2.0, nan, 0.0, nan, 1.0, nan, 2.0, nan, nan, 0.0, nan, 2.0, 2.0, 2.0, nan, 0.0, 2.0, 0.0, nan, nan, 1.0, 2.0, 2.0, 0.0, 1.0, 0.0, 0.0, nan, 1.0, nan, 2.0, 0.0, nan, 0.0, 1.0, 0.0, 0.0, nan, 2.0, 0.0, 0.0, 0.0, 0.0, nan, nan, 1.0], 12: [nan, nan, 2.0, nan, 0.0, 0.0, 0.0, 0.0, 1.0, nan, 0.0, 0.0, 0.0, nan, 0.0, 2.0, nan, 1.0, 2.0, 0.0, nan, nan, 0.0, 2.0, 2.0, 0.0, 0.0, nan, 0.0, 2.0, nan, 0.0, 0.0, 0.0, 0.0, nan, 1.0, 0.0, nan, nan, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0], 13: [0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, nan, 0.0, 1.0, 0.0, 1.0, nan, nan, 1.0, 0.0, 2.0, nan, 0.0, 2.0, nan, 2.0, nan, 0.0, nan, 1.0, 2.0, 0.0, nan, 0.0, 0.0, nan, 2.0, 0.0, nan, 1.0, 0.0, nan, nan, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0], 14: [0.0, nan, 2.0, 0.0, 0.0, 1.0, nan, 0.0, nan, 2.0, 0.0, 0.0, nan, 0.0, nan, 1.0, 1.0, 2.0, nan, 2.0, 0.0, 0.0, nan, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 0.0, nan, nan, nan, 2.0, 2.0, 1.0, nan, 0.0, nan, nan, 1.0, 1.0, nan, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0], 15: [1.0, 1.0, 0.0, nan, 0.0, 1.0, nan, nan, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, nan, nan, 2.0, 0.0, nan, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, nan, nan, 2.0, 0.0, 0.0, nan, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, nan, 2.0, 1.0, nan, nan, 0.0, nan], 16: [0.0, nan, 0.0, nan, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, nan, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 0.0, 2.0, nan, nan, 2.0, nan, nan, nan, nan, nan, 0.0, nan, nan, nan, 0.0, 0.0, 0.0, nan, nan, 0.0, nan, 2.0, 0.0, 0.0, nan, 2.0, nan, 1.0], 17: [0.0, 2.0, 0.0, nan, 1.0, 1.0, 0.0, nan, 1.0, nan, 1.0, 2.0, nan, 0.0, nan, 0.0, 2.0, 2.0, 1.0, 1.0, nan, nan, nan, 0.0, 2.0, nan, 1.0, 1.0, nan, 0.0, 0.0, 0.0, nan, nan, nan, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, nan, 2.0, nan, 2.0, nan, 2.0, nan, 2.0], 18: [1.0, 0.0, 0.0, nan, 1.0, nan, nan, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, nan, nan, 0.0, 2.0, 2.0, nan, 1.0, 0.0, 1.0, 0.0, nan, nan, 0.0, 1.0, 1.0, 2.0, nan, 2.0, 0.0, 1.0, nan, 0.0, 0.0, 1.0, nan, 1.0, 2.0, nan, nan, 0.0, nan, 2.0, 0.0, nan, nan, 0.0], 19: [0.0, 0.0, nan, 1.0, nan, nan, 1.0, nan, 0.0, 1.0, nan, 2.0, 1.0, 0.0, nan, 0.0, 1.0, 2.0, 0.0, 1.0, nan, 0.0, 0.0, 1.0, nan, 2.0, 0.0, nan, 0.0, 0.0, 1.0, 1.0, nan, 0.0, 2.0, 2.0, 1.0, nan, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, nan, 0.0, nan, 0.0, 0.0], 20: [2.0, 0.0, 0.0, 0.0, 1.0, nan, 0.0, nan, 1.0, 0.0, nan, 1.0, 0.0, 1.0, nan, 2.0, 0.0, 1.0, nan, nan, 0.0, 0.0, 0.0, nan, nan, 0.0, 0.0, 2.0, nan, nan, 1.0, nan, 0.0, 1.0, nan, 0.0, nan, 1.0, 2.0, 0.0, nan, 0.0, 1.0, 2.0, nan, nan, 0.0, 0.0, nan, 2.0], 21: [nan, 1.0, 2.0, nan, 1.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 0.0, nan, nan, 2.0, 2.0, 0.0, 2.0, 1.0, nan, nan, 2.0, 2.0, 0.0, 2.0, 1.0, nan, nan, nan, 0.0, 0.0, 1.0, nan, nan, 1.0, 1.0, 0.0, nan, 0.0, 2.0, 0.0, 0.0, 0.0, nan, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0], 22: [nan, 2.0, nan, nan, nan, 0.0, 2.0, nan, nan, nan, 0.0, 0.0, 1.0, 1.0, nan, nan, nan, 1.0, 1.0, 0.0, nan, nan, 2.0, 2.0, 2.0, 0.0, 0.0, nan, 2.0, 0.0, nan, 0.0, 1.0, 0.0, 1.0, nan, 0.0, 0.0, nan, 0.0, 1.0, 0.0, nan, nan, 0.0, nan, 1.0, nan, nan, nan], 23: [nan, 1.0, 0.0, 0.0, nan, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, nan, nan, 2.0, 1.0, 0.0, 1.0, nan, nan, 2.0, 2.0, 1.0, nan, 1.0, nan, 2.0, nan, 1.0, 2.0, nan, 0.0, nan, nan, 0.0, 1.0, 1.0, nan, 0.0, nan, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], 24: [0.0, 0.0, nan, 0.0, 0.0, 0.0, nan, nan, nan, 1.0, 1.0, nan, 0.0, 0.0, 0.0, 2.0, nan, nan, 0.0, 0.0, nan, 0.0, 0.0, nan, nan, nan, 0.0, 1.0, 1.0, 0.0, 2.0, nan, nan, 0.0, 0.0, 0.0, nan, 0.0, 0.0, nan, nan, 1.0, 0.0, 0.0, 0.0, nan, nan, nan, 0.0, 0.0], 25: [0.0, 0.0, 1.0, nan, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, nan, 2.0, 2.0, 1.0, 0.0, 1.0, 0.0, nan, 0.0, nan, 2.0, nan, 1.0, 0.0, 0.0, 2.0, nan, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, nan, 2.0, 2.0, 0.0, 2.0, nan, nan, 0.0, 0.0, 2.0, nan], 26: [2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, nan, 1.0, 0.0, 0.0, 1.0, nan, 1.0, 0.0, nan, 1.0, 2.0, nan, 2.0, 0.0, 0.0, nan, 0.0, nan, nan, 1.0, nan, nan, nan, 0.0, 2.0, nan, nan, 1.0, nan, nan, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 2.0, 0.0, 2.0, nan, 0.0, 1.0, 2.0], 27: [2.0, 0.0, 0.0, 0.0, 0.0, nan, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 1.0, nan, 1.0, 1.0, nan, 0.0, nan, 0.0, 0.0, nan, nan, 1.0, 0.0, nan, 0.0, 2.0, 2.0, 0.0, nan, 1.0, 0.0, nan, nan, 0.0, nan, nan, nan, 0.0, 0.0, 0.0, nan, nan, 0.0, nan, 0.0, nan, nan], 28: [0.0, 2.0, nan, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, nan, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, nan, 1.0, 0.0, nan, 2.0, 0.0, 0.0, nan, 0.0, 0.0, 0.0, 0.0, 2.0, nan, 1.0, 0.0, 1.0, 2.0, nan, 2.0, 1.0, 0.0, nan, 0.0, 0.0, 1.0, nan, 0.0], 29: [0.0, 1.0, 0.0, nan, 0.0, nan, 2.0, nan, nan, 0.0, nan, 0.0, 2.0, nan, nan, 0.0, nan, 0.0, nan, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, nan, 0.0, 0.0, 0.0, 0.0, 1.0, nan, 1.0, 0.0, nan, 1.0, nan, nan, 2.0, 1.0, 0.0, nan, 1.0, 1.0, 1.0], 30: [nan, 0.0, nan, 0.0, 0.0, nan, 2.0, 0.0, nan, 0.0, 1.0, nan, nan, 0.0, nan, 2.0, nan, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, nan, 1.0, nan, nan, nan, 0.0, nan, nan, nan, 0.0, nan, 0.0, 0.0, 2.0, 0.0, 2.0, nan, 0.0, 0.0, nan, nan, 2.0, 2.0, 0.0, nan, 0.0, 1.0], 31: [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, nan, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, nan, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, nan, nan, 2.0, 2.0, 0.0, 1.0, nan, nan, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, nan, 2.0, nan, nan, nan, nan, nan, nan], 32: [1.0, nan, nan, 1.0, 1.0, 2.0, 0.0, 2.0, nan, 0.0, 0.0, 0.0, nan, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, nan, 1.0, nan, 1.0, 0.0, nan, 2.0, nan, 0.0, 0.0, 0.0, 0.0, nan, 2.0, nan, 1.0, 2.0, 2.0, 2.0, 0.0, 0.0, 1.0, nan, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, nan, 2.0], 33: [nan, nan, nan, nan, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, nan, 1.0, nan, 1.0, 2.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 0.0, nan, 2.0, 1.0, 1.0, nan, nan, 1.0, 0.0, 2.0, nan, 1.0, 0.0, 2.0, 0.0, nan, 0.0, 2.0, 0.0, 1.0, 0.0, nan, 2.0, nan, 0.0], 34: [1.0, 0.0, nan, 0.0, nan, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, nan, 2.0, nan, nan, 0.0, 1.0, 0.0, 0.0, 1.0, nan, 2.0, 2.0, 0.0, nan, 2.0, 0.0, 0.0, 0.0, 2.0, nan, 2.0, nan, nan, 0.0, 0.0, 0.0, 0.0, nan, 2.0, nan, nan, 0.0, 0.0, 2.0, nan], 35: [nan, 0.0, nan, 2.0, nan, 0.0, 2.0, nan, nan, 2.0, nan, nan, nan, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, nan, nan, nan, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, nan, nan, 0.0, 0.0, 2.0, 0.0, nan, 2.0, 0.0, nan, 1.0], 36: [1.0, nan, 1.0, 0.0, nan, nan, nan, nan, nan, nan, 0.0, 0.0, nan, 2.0, 0.0, 0.0, nan, 2.0, 0.0, nan, 2.0, nan, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, nan, 0.0, 2.0, 0.0, 2.0, 0.0, nan, 0.0, 0.0, nan, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, nan, nan, 0.0, 1.0, nan], 37: [1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 1.0, 0.0, nan, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, nan, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, nan, nan, 0.0, 0.0, 0.0, 1.0, nan, 0.0, 1.0, 2.0, 2.0, 0.0, 1.0, nan, 2.0, nan, nan, 0.0, nan, 0.0, 0.0, 1.0, nan, nan, 0.0, nan, 1.0, nan], 38: [nan, 1.0, 0.0, 0.0, nan, nan, nan, 2.0, nan, nan, nan, nan, 2.0, 0.0, 0.0, 1.0, nan, nan, nan, 1.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, nan, 1.0, nan, nan, 1.0, 2.0, 0.0, nan, nan, nan, nan, 1.0, 0.0, 2.0, 2.0, 2.0, 1.0, 0.0, 0.0, 2.0, 2.0, nan, nan, nan], 39: [nan, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, nan, 1.0, nan, 0.0, 2.0, nan, 1.0, 2.0, nan, 0.0, 0.0, 0.0, 0.0, nan, 1.0, 0.0, 0.0, nan, 1.0, 0.0, 2.0, 2.0, 0.0, 1.0, 2.0, nan, nan, 0.0, 0.0, 0.0, 1.0, 0.0, nan, 0.0, 2.0, 0.0, 0.0, nan], 40: [1.0, 1.0, 0.0, 1.0, nan, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, nan, 0.0, nan, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, nan, 0.0, 1.0, 0.0, 0.0, nan, 0.0, 0.0, 2.0, 0.0, 0.0, nan, nan, 0.0, 0.0, nan, nan, 2.0, 0.0, nan, 0.0, nan, nan, nan, 0.0, nan], 41: [1.0, nan, 0.0, 0.0, 0.0, 0.0, 0.0, nan, nan, 1.0, 0.0, 2.0, 2.0, 1.0, nan, nan, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, nan, nan, 2.0, 2.0, 0.0, nan, 2.0, nan, nan, nan, 1.0, 1.0, 0.0, nan, 0.0, nan, nan, nan, 1.0, 0.0, nan, 0.0, 1.0, 2.0, 0.0, nan, nan, 0.0], 42: [nan, 2.0, 1.0, nan, nan, 0.0, 2.0, 0.0, 0.0, nan, 1.0, nan, nan, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, nan, nan, nan, nan, nan, 1.0, 0.0, nan, nan, nan, 0.0, nan, nan, nan, nan, 0.0, nan, nan, 0.0, 2.0, 0.0, nan, nan, 1.0, nan, 2.0, 1.0, 0.0, nan, nan], 43: [0.0, nan, nan, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, nan, 0.0, nan, 0.0, 1.0, nan, 0.0, 0.0, 1.0, 2.0, nan, 0.0, 0.0, 1.0, 0.0, 1.0, nan, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, nan, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, nan, 1.0, 0.0, 1.0, 0.0, 1.0], 44: [2.0, 2.0, 1.0, 1.0, 0.0, 0.0, nan, 1.0, 0.0, 0.0, 1.0, nan, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, nan, nan, 2.0, 1.0, 1.0, 2.0, 2.0, nan, 0.0, 1.0, 0.0, nan, nan, nan, 0.0, 1.0, 1.0, 2.0, nan, 0.0, 0.0, 1.0, 1.0, nan, 2.0, 0.0, 0.0, nan], 45: [nan, nan, 2.0, 0.0, nan, 0.0, nan, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, nan, 0.0, nan, 0.0, 1.0, nan, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, nan, 2.0, nan, nan, 0.0, 2.0, 2.0, 0.0, nan, 2.0, nan, nan, nan, 2.0, nan, 0.0, 2.0, nan, nan, nan, 1.0], 46: [nan, nan, 0.0, 0.0, nan, 0.0, 2.0, nan, 0.0, 0.0, 0.0, 0.0, 0.0, nan, 2.0, 2.0, nan, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, nan, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, nan, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0], 47: [2.0, 2.0, 0.0, 1.0, 2.0, nan, nan, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 2.0, nan, 1.0, nan, 0.0, 0.0, 2.0, 1.0, nan, 1.0, 0.0, 2.0, 2.0, 0.0, nan, 2.0, 0.0, 1.0, nan, 0.0, 2.0, 0.0, 0.0, nan, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0], 48: [2.0, 2.0, 0.0, 0.0, 2.0, nan, nan, nan, 0.0, 0.0, nan, nan, nan, 2.0, 2.0, nan, 0.0, nan, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, nan, 1.0, 0.0, 1.0, nan, 0.0, nan, 1.0, nan, nan, 0.0, nan, 0.0, 1.0, nan, 2.0, 2.0, 1.0, 2.0, nan, nan, 2.0, nan, nan, 0.0, 0.0], 49: [2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 0.0, nan, nan, 2.0, nan, 0.0, nan, nan, 1.0, 0.0, 0.0, 2.0, nan, 2.0, 2.0, 0.0, 1.0, nan, 2.0, 1.0, nan, nan, nan, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 0.0, nan, 2.0, 2.0, 0.0, 0.0, nan, 2.0, 1.0, 1.0]}\n"
     ]
    }
   ],
   "source": [
    "col_names_and_vectors = {i: df.loc[:, i].tolist() for i in range(df.shape[1])}\n",
    "\n",
    "print(col_names_and_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9nv5y7PcIjmO"
   },
   "source": [
    "* Create a list whose keys are the column number and values are themselves a list with keys: \"min\" whose value is the minimum of the column, \"max\" whose value is the maximum of the column, \"pct_missing\" is the proportion of missingness in the column and \"first_NA\" whose value is the row number of the first time the NA appears. In R this was accomplished using lappy. In Python we will use dictionary comprehension in tandem with Numpy and Pandas operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PA9Y8De_JBKy",
    "outputId": "b2414bb1-aba9-4798-9213-1be8cf957deb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.32, 'first_NA': 1}, 1: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.34, 'first_NA': 0}, 2: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.24, 'first_NA': 0}, 3: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.36, 'first_NA': 2}, 4: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.28, 'first_NA': 5}, 5: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.32, 'first_NA': 4}, 6: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.28, 'first_NA': 1}, 7: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.22, 'first_NA': 4}, 8: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.46, 'first_NA': 0}, 9: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.24, 'first_NA': 6}, 10: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.3, 'first_NA': 0}, 11: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.3, 'first_NA': 1}, 12: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.18, 'first_NA': 9}, 13: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.24, 'first_NA': 2}, 14: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.32, 'first_NA': 9}, 15: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.34, 'first_NA': 1}, 16: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.32, 'first_NA': 1}, 17: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.32, 'first_NA': 1}, 18: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.34, 'first_NA': 0}, 19: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.32, 'first_NA': 2}, 20: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.38, 'first_NA': 0}, 21: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.3, 'first_NA': 2}, 22: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.4, 'first_NA': 1}, 23: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.32, 'first_NA': 1}, 24: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.16, 'first_NA': 0}, 25: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.4, 'first_NA': 1}, 26: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.26, 'first_NA': 0}, 27: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.34, 'first_NA': 2}, 28: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.2, 'first_NA': 0}, 29: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.4, 'first_NA': 7}, 30: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.28, 'first_NA': 7}, 31: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.26, 'first_NA': 6}, 32: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.36, 'first_NA': 0}, 33: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.44, 'first_NA': 1}, 34: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.34, 'first_NA': 1}, 35: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.4, 'first_NA': 0}, 36: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.28, 'first_NA': 7}, 37: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.32, 'first_NA': 0}, 38: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.3, 'first_NA': 1}, 39: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.28, 'first_NA': 1}, 40: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.36, 'first_NA': 3}, 41: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.32, 'first_NA': 1}, 42: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.24, 'first_NA': 0}, 43: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.26, 'first_NA': 0}, 44: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.3, 'first_NA': 1}, 45: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.36, 'first_NA': 0}, 46: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.32, 'first_NA': 3}, 47: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.38, 'first_NA': 3}, 48: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.36, 'first_NA': 1}, 49: {'min': 0.0, 'max': 0.0, 'pct_missing': 0.42, 'first_NA': 0}}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(R)\n",
    "\n",
    "col_stats = {\n",
    "    i:{\n",
    "        \"min\" : df.iloc[:, i].min(skipna=True),\n",
    "        \"max\" : df.iloc[:, i].min(skipna= True),\n",
    "        \"pct_missing\" : df.iloc[:, i].isna().mean(),\n",
    "        \"first_NA\" : df.iloc[:, i].isna().idxmax() if df.iloc[:, i].isna().any() else None\n",
    "    }\n",
    "    for i in range(df.shape[1])\n",
    "}\n",
    "\n",
    "print(col_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ODDPcnZkJ5NC"
   },
   "source": [
    "* Set a seed and then create a vector `v` consisting of a sample of 1,000 iid normal realizations with mean -10 and variance 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nw2iaLlhJQqZ",
    "outputId": "f93873f8-979a-40c2-c95a-3d84a98fef3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.59052570e+02, -5.65937371e+01, -6.71798363e+00,  3.07516283e+01,\n",
       "       -8.88923029e+01, -9.79344271e+00, -1.00890386e+01, -1.85472431e+02,\n",
       "        9.17658006e+01,  5.00498516e+01, -7.25428974e+01, -2.71548261e+01,\n",
       "        4.05299374e+01, -3.61356415e+01, -3.42749079e+01, -1.55324141e+02,\n",
       "        4.54580312e+01,  2.38809053e+00,  1.74459924e+01, -1.62652453e+02,\n",
       "        1.55069969e+02,  5.43355355e+00, -4.87139943e+01,  1.92907222e+02,\n",
       "       -1.45386030e+01, -1.55067870e+02, -5.05227855e+01, -2.38831510e+02,\n",
       "        9.49396549e+01, -5.16474319e+01, -8.42553525e+01,  9.72470132e+01,\n",
       "       -1.75107559e+02,  4.35429356e+01, -2.16441480e+02, -7.62159340e+01,\n",
       "       -1.30421985e+02,  1.36197563e+02,  1.66616088e+02, -4.29413752e+01,\n",
       "        7.40733242e+01, -2.79986401e+01,  4.68061887e+01, -8.52837196e+01,\n",
       "       -1.80833920e+02, -1.90309866e+02,  2.83121852e+01,  2.14759505e+02,\n",
       "        1.69411631e+01, -6.24604619e+01,  1.81201886e+02,  1.37301847e+01,\n",
       "        1.43398521e-01,  1.52577736e+01, -2.32377198e+01, -4.09476341e+01,\n",
       "       -1.53496347e+02,  4.01624123e+01, -1.94775450e+01,  1.09308592e+02,\n",
       "       -4.68818468e+01, -2.00636988e+02, -1.99610632e+01,  1.59953730e+02,\n",
       "       -4.83423123e+01, -9.89856861e+01, -1.29359192e+02, -1.15001681e+02,\n",
       "       -4.00193737e+01, -1.27998209e+02,  1.39763912e+02, -3.82635236e+01,\n",
       "        8.64837149e-01,  1.33823952e+02,  1.40331852e+02, -3.12732967e+01,\n",
       "        2.31974215e+01,  6.35026584e+01, -2.92855460e+01, -1.87801285e+02,\n",
       "        5.54705704e+01,  7.94352305e+01,  3.15502614e+01, -1.02354466e+02,\n",
       "       -2.96027312e+01, -6.90769819e+01, -3.99711237e+01,  1.19688519e+02,\n",
       "        1.42957963e+02,  5.69418193e+01,  4.48745120e+01,  5.76628990e+01,\n",
       "       -1.12242187e+01, -1.75663461e+01, -7.73645187e+01, -1.55867450e+01,\n",
       "        2.15994699e+02,  7.69039329e+01, -4.42117023e+01, -5.71926652e+01])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(7)\n",
    "v = np.asarray(np.random.normal(loc=-10, scale= 100, size= 100))\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tnKYRW5AKI7I"
   },
   "source": [
    "* Repeat this exercise by resetting the seed to ensure you obtain the same results. You can use the random module built in python or random.seed from numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1QHAam3_KCdD",
    "outputId": "9dd29024-89b8-4ab5-d150-0999b39876ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(7)\n",
    "c = np.asarray(np.random.normal(loc=-10, scale= 100, size= 100))\n",
    "print(c == v) # -> True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RH1j1mgNKnc1"
   },
   "source": [
    "* Find the average of `v` and the standard error of `v`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HWJZzmV3KPww",
    "outputId": "72de329e-cfa0-485a-f99f-afd0714804ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101.87395460972256"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(v)\n",
    "np.std(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rH-Sf7vqLBxz"
   },
   "source": [
    "* Find the 5%ile of `v` and use the `norm` function from scipy.stats to compute what it theoretically should be. Is the estimate about what is expected by theory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aBMMfyNBLAzS",
    "outputId": "644d6a5c-9cea-4d4b-b7b2-a21b82c6a347"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-174.48536269514727"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "norm.ppf(0.05,loc = -10, scale = 100)\n",
    "\n",
    "\n",
    "#help(norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8R9DHC_yLq57"
   },
   "source": [
    "* What is the percentile of `v` that corresponds to the value 0? What should it be theoretically? Is the estimate about what is expected by theory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zf-4WAiKLefJ",
    "outputId": "e131bf75-069c-42ba-b577-7b119d641679"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.539827837277029"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.cdf(x= 0, loc = -10, scale = 100)\n",
    "#help(norm.cdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "494OABRdM6CZ"
   },
   "source": [
    "* Create a function `my_reverse` which takes as required input a vector `v` and returns the vector in reverse where the first entry is the last entry, etc. No function calls are allowed inside your function otherwise that would defeat the purpose of the exercise! (Yes, there is a base R function that does this called `rev`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FNXIBb6ZM2yq",
    "outputId": "175eaaa6-2a71-46c5-b22c-9fc94d83ef15"
   },
   "outputs": [],
   "source": [
    "def my_reverse(v):\n",
    "    reverse = v[::-1]\n",
    "    return reverse\n",
    "\n",
    "#I'll be honest, I did not see the next question. But string slicing doesn't count as a function call does it?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lCutgH2kOMDd"
   },
   "source": [
    " * Built in methods in python to reverse a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_F67NrC8N5nl",
    "outputId": "38ec40dc-3f57-4ada-d253-045c1b4bf985"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 4, 3, 2, 1]\n",
      "[5, 4, 3, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "#reverse using slicing\n",
    "v = [1, 2, 3, 4, 5]\n",
    "v_reversed = v[::-1]\n",
    "print(v_reversed)\n",
    "\n",
    "#using the .reverse method\n",
    "v = [1, 2, 3, 4, 5]\n",
    "v.reverse()\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4VZDnJUFNp9d"
   },
   "source": [
    "* Create a function `flip_matrix` which takes as required input a matrix, an argument `dim_to_rev` that returns the matrix with the rows in reverse order or the columns in reverse order depending on the `dim_to_rev` argument. Let the default be the dimension of the matrix that is greater."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KJzPP76INONa",
    "outputId": "44dd9b1f-9e5b-48ed-edcb-37be5f026df9"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (4016932303.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[157], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    if v.shape[0] > v.shape[1]\u001b[0m\n\u001b[1;37m                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "f = np.asarray(v)\n",
    "def flip_matrix(v,dim_to_rev = None):\n",
    "    rows, cols = v.shape\n",
    "\n",
    "    if dim_to_rev is None\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1n-VzTJTPpoU"
   },
   "source": [
    "* Create a list named `my_list` with keys \"A\", \"B\", ... where the entries are arrays of size 1, 2 x 2, 3 x 3 x 3, etc. Fill the array with the numbers 1, 2, 3, etc. Make 8 entries according to this sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vGYjxbVcPNLN",
    "outputId": "165888fb-2728-4a4c-daf3-5183e6e1c66b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1, 2]\n",
      "[1, 2, 3]\n",
      "[1, 2, 3, 4]\n",
      "[1, 2, 3, 4, 5]\n",
      "[1, 2, 3, 4, 5, 6]\n",
      "[1, 2, 3, 4, 5, 6, 7]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "{'A': [1], 'B': [1, 2], 'C': [1, 2, 3], 'D': [1, 2, 3, 4], 'E': [1, 2, 3, 4, 5], 'F': [1, 2, 3, 4, 5, 6], 'G': [1, 2, 3, 4, 5, 6, 7], 'H': [1, 2, 3, 4, 5, 6, 7, 8]}\n"
     ]
    }
   ],
   "source": [
    "list_keys = ('A','B','C','D','E','F','G','H')\n",
    "list_values = [1,2,3,4,5,6,7,8]\n",
    "my_list = {}\n",
    "for elem in range(len(list_keys)):\n",
    "    my_list[list_keys[elem]] = list(range(1, list_values[elem] + 1))\n",
    "    print(my_list[list_keys[elem]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZExH8G6Qr-s"
   },
   "source": [
    "* Run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iV2anQ8cQBw_",
    "outputId": "c9bf96a4-5f98-41f8-9ef6-2b95f9ccfeb9"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sizes = {key: sys.getsizeof(value) for key, value in my_list.items()}\n",
    "\n",
    "\n",
    "# Print the sizes\n",
    "for key, size in sizes.items():\n",
    "    print(f\"Key: {key}, Size: {size} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GG32YkXnSxqM"
   },
   "source": [
    "* Create vector `v` consisting of all numbers from -100 to 100 and test using the second line of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LnkySK_uSSlb",
    "outputId": "b0de8d3e-cc41-4123-f08c-0a03e395b3d5"
   },
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "num_vec = np.asarray(range(-100,101))\n",
    "\n",
    "num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dH4AjtFUVphe"
   },
   "source": [
    "* Test the `my_reverse` function using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zAJAaua1SbqD",
    "outputId": "f1922dde-f8d2-47a8-edd5-f0d70144d9c2"
   },
   "outputs": [],
   "source": [
    "# Test the function\n",
    "v = list(range(1, 11))\n",
    "v_reversed = my_reverse(v)\n",
    "print(v)\n",
    "print(v_reversed)\n",
    "type(v_reversed)\n",
    "\n",
    "assert my_reverse(v) == v[::-1], \"my_reverse failed for numerical vector\"\n",
    "\n",
    " # Test with character vector\n",
    "v_char = [\"A\", \"B\", \"C\"]\n",
    "assert my_reverse(v_char) == v_char[::-1], \"my_reverse failed for character vector\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B4ch5SmkVzfz"
   },
   "source": [
    "## A little about strings\n",
    "\n",
    "* Use the `re.split` function by importing the re module and `random` from the random module to put the sentences in the string `lorem` below in random order. You will also need to manipulate the output of `re.split` which is a list. You may need to learn basic concepts of regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tVRqWzFCVzAX",
    "outputId": "c58a0650-9033-4ef6-d02e-4f3f6ee21251"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mauris at sodales augue.', 'Donec at tempor erat.', 'Morbi faucibus ligula id massa ultricies viverra.', 'Mauris at sodales augue.', 'Morbi posuere varius volutpat.', 'Integer dapibus mi lectus, eu posuere arcu ultricies in.', 'Donec at tempor erat.', 'Donec at tempor erat.', 'Lorem ipsum dolor sit amet, consectetur adipiscing elit.', 'Cras suscipit id nibh lacinia elementum.', 'Curabitur est augue, congue eget quam in, scelerisque semper magna.', 'Morbi faucibus ligula id massa ultricies viverra.', 'Aenean nulla ante, iaculis sed vehicula ac, finibus vel arcu.', 'Integer dapibus mi lectus, eu posuere arcu ultricies in.', 'Morbi posuere varius volutpat.', 'Morbi posuere varius volutpat.', 'Aenean nulla ante, iaculis sed vehicula ac, finibus vel arcu.', 'Mauris at sodales augue.', 'Morbi posuere varius volutpat.']\n",
      "['Lorem ipsum dolor sit amet, consectetur adipiscing elit.', 'Morbi posuere varius volutpat.', 'Morbi faucibus ligula id massa ultricies viverra.', 'Donec vehicula sagittis nisi non semper.', 'Donec at tempor erat.', 'Integer dapibus mi lectus, eu posuere arcu ultricies in.', 'Cras suscipit id nibh lacinia elementum.', 'Curabitur est augue, congue eget quam in, scelerisque semper magna.', 'Aenean nulla ante, iaculis sed vehicula ac, finibus vel arcu.', 'Mauris at sodales augue.']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "\n",
    "lorem = \"\"\"Lorem ipsum dolor sit amet, consectetur adipiscing elit.\n",
    "Morbi posuere varius volutpat. Morbi faucibus ligula id massa ultricies viverra.\n",
    "Donec vehicula sagittis nisi non semper. Donec at tempor erat.\n",
    "Integer dapibus mi lectus, eu posuere arcu ultricies in.\n",
    "Cras suscipit id nibh lacinia elementum. Curabitur est augue, congue eget quam in, scelerisque semper magna.\n",
    "Aenean nulla ante, iaculis sed vehicula ac, finibus vel arcu. Mauris at sodales augue.\"\"\"\n",
    "\n",
    "lorem_words = list(re.split(string=lorem, pattern= \"(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)(\\s|[A-Z].*)\", ))\n",
    "\n",
    "lorem_words_clean = [elem for elem in lorem_words if elem not in {'\\n', ' ', ','}]\n",
    "        \n",
    "\n",
    "print(random.choices(lorem_words_clean, k= len(lorem_words)))\n",
    "\n",
    "print(lorem_words_clean)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40eoQu9LWrBo"
   },
   "source": [
    "* You have a set of names divided by gender (M / F) and generation (Boomer / GenX / Millenial):\n",
    "\n",
    "M / Boomer      \"Theodore, Bernard, Gene, Herbert, Ray, Tom, Lee, Alfred, Leroy, Eddie\"\n",
    "\n",
    "M / GenX        \"Marc, Jamie, Greg, Darryl, Tim, Dean, Jon, Chris, Troy, Jeff\"\n",
    "\n",
    "M / Millennial  \"Zachary, Dylan, Christian, Wesley, Seth, Austin, Gabriel, Evan, Casey, Luis\"\n",
    "\n",
    "F / Boomer      \"Gloria, Joan, Dorothy, Shirley, Betty, Dianne, Kay, Marjorie, Lorraine, Mildred\"\n",
    "\n",
    "F / GenX        \"Tracy, Dawn, Tina, Tammy, Melinda, Tamara, Tracey, Colleen, Sherri, Heidi\"\n",
    "\n",
    "F / Millennial  \"Samantha, Alexis, Brittany, Lauren, Taylor, Bethany, Latoya, Candice, Brittney, Cheyenne\"\n",
    "\n",
    "Create python dictionary to store this data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KMpxbhglWYoA",
    "outputId": "334af4d7-a902-4c79-c3fe-03988d6654ab"
   },
   "outputs": [],
   "source": [
    "male_boomers = list(\"Theodore, Bernard, Gene, Herbert, Ray, Tom, Lee, Alfred, Leroy, Eddie\".split(\", \"))\n",
    "male_genx = list(\"Marc, Jamie, Greg, Darryl, Tim, Dean, Jon, Chris, Troy, Jeff\".split(\", \"))\n",
    "male_mills = list(\"Zachary, Dylan, Christian, Wesley, Seth, Austin, Gabriel, Evan, Casey, Luis\".split(\", \"))\n",
    "\n",
    "female_boomers = list(\"Gloria, Joan, Dorothy, Shirley, Betty, Dianne, Kay, Marjorie, Lorraine, Mildred\".split(\", \"))\n",
    "female_genx = list(\"Tracy, Dawn, Tina, Tammy, Melinda, Tamara, Tracey, Colleen, Sherri, Heidi\".split(\", \"))\n",
    "female_mills = list(\"Samantha, Alexis, Brittany, Lauren, Taylor, Bethany, Latoya, Candice, Brittney, Cheyenne\".split(\", \"))\n",
    "\n",
    "people_dict = {\n",
    "    \"Male\" : {\n",
    "        \"Boomer\" : male_boomers,\n",
    "        \"GenX\" : male_genx,\n",
    "        \"Millenial\" : male_mills\n",
    "    },\n",
    "    \"Female\" : {\n",
    "        \"Boomer\" : female_boomers,\n",
    "        \"GenX\" : female_genx,\n",
    "        \"Millenial\" : female_mills\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "people_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mE0YVNtiWzC2"
   },
   "source": [
    "* Now cleanup the namespace by deleting all stored objects and functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cqUJBY1uWzty",
    "outputId": "7a5eae8c-2613-4e44-a460-25d06818e769"
   },
   "outputs": [],
   "source": [
    "\n",
    "delete"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
